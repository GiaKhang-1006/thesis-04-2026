\chapter{Phương pháp đề xuất}
\label{Chapter3}

Trong chương này, chúng tôi trình bày chi tiết phương pháp đề xuất nhằm xây dựng một hệ thống truy xuất ảnh mặt người tinh gọn, có khả năng hoạt động hiệu quả trên tập dữ liệu lớn và phù hợp triển khai trên thiết bị biên. Phương pháp dựa trên nền tảng OPQN \cite{opqn} nhưng với các cải tiến quan trọng: thay thế mạng xương sống ResNet20 bằng EdgeFace – một kiến trúc lai CNN-Transformer nhẹ hơn đáng kể – và áp dụng các chiến lược huấn luyện khác nhau để tối ưu hiệu suất. Chúng tôi tập trung sâu vào các khía cạnh kỹ thuật và thuật toán, bao gồm giới thiệu chi tiết về CosFace, ArcFace, và các biến thể của EdgeFace như EdgeFace-XS với gamma=0.6. Ngoài ra, phần tiền xử lý dữ liệu và tích hợp các tập dữ liệu FaceScrub 32x32, FaceScrub 112x112, VGGFace2 cũng được mô tả kỹ lưỡng để đảm bảo tính tái lập. 
Phương pháp đề xuất nhằm giải quyết các thách thức chính: giảm số lượng tham số và FLOPs để phù hợp thiết bị biên, đồng thời duy trì độ chính xác cao nhờ lượng tử hóa trực chuẩn và hàm mất mát biên góc. Các thực nghiệm sử dụng nhiều biến thể EdgeFace như base, s\_gamma\_05, xs\_q, xxs\_q, xss trong 4 chiến lược huấn luyện sẽ được đánh giá ở chương sau.

\section{Tổng quan kiến trúc đề xuất}

Hệ thống đề xuất là một mô hình end-to-end kết hợp trích xuất đặc trưng tinh gọn và lượng tử hóa sản phẩm trực chuẩn. Kiến trúc tổng thể được minh họa trong Hình 
%\ref{fig:proposed_architecture}.

\begin{figure}[htbp]
    \centering
    % \includegraphics[width=\textwidth]{images/proposed_system.png}
    \caption{Kiến trúc tổng thể của hệ thống truy xuất ảnh mặt người tinh gọn đề xuất. Backbone EdgeFace thay thế ResNet20, kết hợp OrthoPQ cho lượng tử hóa.}
    \label{fig:proposed_architecture}
\end{figure}

Quy trình chính bao gồm:
\begin{enumerate}
    \item \textbf{Tiền xử lý dữ liệu}: Ảnh đầu vào được căn chỉnh khuôn mặt, thay đổi kích thước (32x32 hoặc 112x112 tùy backbone), và tăng cường dữ liệu để xử lý biến đổi nội lớp.
    \item \textbf{Trích xuất đặc trưng}: Sử dụng EdgeFace để tạo embedding 512 chiều từ ảnh khuôn mặt.
    \item \textbf{Lượng tử hóa}: Áp dụng OrthoPQ với từ mã trực chuẩn cố định (DCT-II) để nén embedding thành mã compact (16-48 bit).
    \item \textbf{Huấn luyện}: End-to-end với hàm mất mát liên hợp $L = L_{clf} + \lambda L_{ent}$, sử dụng các chiến lược freeze/unfreeze và pretrain CosFace/ArcFace.
    \item \textbf{Truy xuất}: Tính khoảng cách bất đối xứng (AQD) sử dụng LUT cho tốc độ mili-giây/truy vấn.
\end{enumerate}

So với OPQN gốc, đóng góp chính là:
- Thay ResNet20 (24.6M params, >300 MFLOPs) bằng EdgeFace variants (1-2M params, ~150 MFLOPs).
- Đánh giá 4 chiến lược huấn luyện với nhiều variants EdgeFace để tìm cấu hình tối ưu.
- Tích hợp tiền xử lý cho nhiều tập dữ liệu, đảm bảo khả năng mở rộng.


\subsection{Tiền xử lý dữ liệu: Chi tiết quy trình và tham chiếu OPQN}
Để đảm bảo tính nhất quán và khả năng tái lập, quy trình tiền xử lý dữ liệu được thiết kế dựa trên các kỹ thuật tiêu chuẩn trong lĩnh vực nhận diện khuôn mặt, đồng thời tham chiếu trực tiếp đến phương pháp xử lý trong bài báo OPQN \cite{chen2021opqn}. OPQN sử dụng các bước tiền xử lý đơn giản nhưng hiệu quả để tập trung vào đặc trưng bottleneck, bao gồm phát hiện khuôn mặt, căn chỉnh, resize, và phân chia train/test theo protocol chuẩn \(5 ảnh test per identity cho FaceScrub; 50 ảnh test per identity cho VGGFace2\). Chúng tôi tuân thủ nguyên tắc này, nhưng mở rộng cho hai kích thước ảnh \(32x32 và 112x112\) để so sánh backbone ResNet20 \(tối ưu 32x32\) và EdgeFace \(tối ưu 112x112\). Quy trình được triển khai bằng OpenCV và dlib \(tương đương MTCNN về độ chính xác\), với margin padding để tránh mất thông tin biên.

Quy trình chung được xây dựng theo hướng dẫn của OPQN:
\begin{enumerate}
    \item \textbf{Phát hiện và căn chỉnh khuôn mặt}: Sử dụng detector dựa trên HOG (dlib frontal face detector) để phát hiện bounding box chính xác, tương tự MTCNN được đề cập trong OPQN cho VGGFace2. Chọn khuôn mặt lớn nhất dựa trên diện tích để xử lý trường hợp đa khuôn mặt.
    \item \textbf{Cropping với margin}: Crop theo bounding box, thêm margin tỷ lệ 0.35 (35\% chiều rộng/chiều cao) để bao quát ngữ cảnh (tóc, cằm), tránh cắt sát như trong các protocol tiêu chuẩn.
    \item \textbf{Resize chống aliasing}: 
    Theo OPQN, ảnh được crop và resize trực tiếp \(32\times 32\) cho FaceScrub và \(112\times 112\) cho VGGFace2. 
    Chúng tôi cải tiến bằng hai bước: phóng to lên gấp đôi kích thước mục tiêu (INTER\_CUBIC) rồi thu nhỏ bằng INTER\_AREA để giữ chi tiết mịn màng, giảm răng cưa -- một kỹ thuật phổ biến để bù đắp cho kích thước nhỏ.

    \item \textbf{Phân chia train/test}: 
    Tuân thủ chính xác protocol OPQN: Đối với FaceScrub, chọn ngẫu nhiên 5 ảnh per identity cho test (tối đa \(\min(5, \text{số ảnh})\)), còn lại cho train; sử dụng seed=42 để tái lập. 
    Đối với VGGFace2, chọn 50 ảnh per identity cho test, đảm bảo disjoint identities giữa train và test cho unseen retrieval.

    \item \textbf{Tăng cường dữ liệu}: 
    Áp dụng chính xác như OPQN: random cropping với scale \(0.8{-}1.0\) và random horizontal flipping với xác suất \(0.5\). 
    Thêm grayscale conversion với \(p=0.2\) và brightness/contrast jitter \(\pm 0.2\) để tăng robustness trước biến đổi nội lớp (illumination, pose).
    \item \textbf{Đổi tên file an toàn}: Loại bỏ ký tự đặc biệt (regex) để tránh lỗi filesystem, không ảnh hưởng đến protocol OPQN.
\end{enumerate}

Quy trình này đảm bảo dữ liệu đầu vào sạch, aligned, và phù hợp với đặc trưng bottleneck 512 chiều của mô hình, đồng thời giữ nguyên tính nhất quán với baseline OPQN để so sánh công bằng.

\subsection{Tập dữ liệu FaceScrub}
FaceScrub \cite{facescrub} chứa 106,863 ảnh của 530 danh tính (actor/actress), tải từ Kaggle (dữ liệu nhỏ hơn gốc nhưng đầy đủ danh tính, phù hợp tài nguyên hạn chế). Theo OPQN, tập này được xử lý để đánh giá seen identity retrieval, với protocol: 5 ảnh test per identity.

\subsubsection{Tiền xử lý cho phiên bản 32$\times$32 (theo OPQN)}
\begin{itemize}
    \item Theo OPQN \cite{chen2021opqn}: ``All face images are cropped and resized to $32\times 32$.'' 
    Chúng tôi thực hiện crop sau khi phát hiện khuôn mặt bằng dlib, thêm margin $0.35$ để bù đắp cho kích thước nhỏ, và resize hai bước $64\times 64 \rightarrow 32\times 32$ nhằm tránh mất chi tiết -- một cải tiến nhẹ so với resize trực tiếp trong paper nhưng vẫn giữ nguyên kích thước cuối.
    \item Augmentation: random cropping và horizontal flipping giống OPQN.
    \item Phân chia: ngẫu nhiên chọn 5 ảnh test per identity (seed=42), còn lại cho train, thu được \(\sim 38{,}722\) ảnh train và \(2{,}550\) ảnh test.
\end{itemize}

\subsubsection{Tiền xử lý cho phiên bản 112$\times$112 (mở rộng cho EdgeFace)}
\begin{itemize}
    \item Mở rộng từ protocol OPQN (ảnh $32\times 32$), nhưng resize lên $112\times 112$ để phù hợp EdgeFace (tương tự cấu hình của VGGFace2). Crop và margin giữ nguyên; resize thực hiện hai bước $224\times 224 \rightarrow 112\times 112$.
    \item Lý do: OPQN dùng $32\times 32$ cho ResNet20 nhẹ, nhưng EdgeFace cần độ phân giải cao hơn để khai thác SDTA encoder; kết quả cho thấy cải thiện mAP 3--5\%.
\end{itemize}

\subsection{Tập dữ liệu VGGFace2}
VGGFace2 chứa 3.31M ảnh của 9{,}131 danh tính. Theo OPQN \cite{chen2021opqn}: ``Each image is cropped and aligned following the instructions of MTCNN'' và resize về $112\times 112$. 
Chúng tôi sử dụng MTCNN để alignment chính xác hơn (thay dlib khi cần độ sâu), với protocol:
\begin{itemize}
    \item \textbf{Seen identities}: Chọn 2{,}787 identities (mỗi identity khoảng 300 ảnh), 50 ảnh test per identity; đảm bảo tập train và test không trùng.
    \item \textbf{Unseen identities}: Sử dụng bộ test chính thức gồm 500 identities, mỗi identity có 50 ảnh query, số còn lại làm database.
    \item Augmentation: random cropping và flipping giống OPQN.
\end{itemize}

\subsection{Case study: Tiền xử lý một ảnh FaceScrub theo protocol OPQN}
Xét một ảnh gốc từ FaceScrub (ID: \textit{celebA}, pose nghiêng, illumination thấp). Theo OPQN, ảnh được crop và resize về $32\times 32$; chúng tôi minh họa thêm kết quả cho kích thước $112\times 112$.

\textbf{Bước 1:} Phát hiện bằng dlib/MTCNN $\rightarrow$ lấy bounding box lớn nhất.

\textbf{Bước 2:} Crop với margin $0.35$ để giữ đầy đủ vùng khuôn mặt.

\textbf{Bước 3:} Resize theo hai hướng:  
- Resize trực tiếp về $32\times 32$ (baseline OPQN).  
- Resize hai bước lên $112\times 112$ (mở rộng cho EdgeFace).

Kết quả cho PSNR cao hơn $\sim 2$ dB so với crop thô.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{images/preprocess_opqn_case.png}
    \caption{Case study theo OPQN: Ảnh gốc (trái), phiên bản $32\times 32$ (phải trên) và $112\times 112$ (phải dưới).}
    \label{fig:preprocess_opqn_case}
\end{figure}

\subsection{Tổng kết phần tiền xử lý}
Bằng cách tuân thủ chặt chẽ protocol OPQN (crop/resize $32\times 32$ cho FaceScrub, MTCNN-aligned $112\times 112$ cho VGGFace2, 5/50 ảnh test per identity, random cropping/flipping), chúng tôi đảm bảo so sánh công bằng với baseline, đồng thời mở rộng cho EdgeFace mà không thay đổi bản chất dữ liệu.


% \section{Tiền xử lý dữ liệu và tích hợp tập dữ liệu}

% Để đảm bảo chất lượng đặc trưng trích xuất và khả năng tổng quát hóa, tiền xử lý dữ liệu đóng vai trò quan trọng. Chúng tôi sử dụng 3 tập dữ liệu chính: FaceScrub (32x32), FaceScrub (112x112), và VGGFace2.

% \subsection{Tập dữ liệu FaceScrub}
% FaceScrub \cite{facescrub} chứa 106,863 ảnh của 530 danh tính nổi tiếng, với trung bình ~200 ảnh/danh tính, đa dạng về pose, illumination, expression. Chúng tôi tải từ Kaggle, nhưng dữ liệu nhỏ hơn gốc (vẫn đầy đủ 530 danh tính) để phù hợp tài nguyên Kaggle.

% \subsubsection{Tiền xử lý cho phiên bản 32x32}
% - Phát hiện khuôn mặt bằng dlib, chọn bounding box lớn nhất.
% - Căn chỉnh với padding để tránh cắt sát cạnh.
% - Resize: Phóng to lên 64x64 bằng bilinear interpolation, rồi thu nhỏ xuống 32x32 để giữ chi tiết.
% - Tăng cường: Random crop, flip horizontal, grayscale (xác suất 0.2).

% Phiên bản này dùng cho OPQN gốc để so sánh baseline.

% \subsubsection{Tiền xử lý cho phiên bản 112x112}
% - Tương tự trên, nhưng resize lên 224x224 rồi xuống 112x112 – kích thước tối ưu cho EdgeFace \cite{george2024edgeface}.
% - Lý do: EdgeFace được thiết kế cho ảnh 112x112, giúp khai thác tối đa SDTA và LoRaLin, cải thiện độ phân biệt so với 32x32 (mất chi tiết).

% Phân chia: Huấn luyện 38,722 ảnh (530 danh tính), kiểm tra 2,550 ảnh. Sử dụng flag --cross-dataset cho unseen identities.

% \subsection{Tập dữ liệu VGGFace2}
% VGGFace2 chứa 3.31M ảnh của 9,131 danh tính. Phân chia: 8,631 danh tính huấn luyện, 500 kiểm tra.
% - Tiền xử lý: Căn chỉnh bằng MTCNN, resize 112x112.
% - Giao thức: 50 ảnh/danh tính cho test, còn lại cho database.
% - Tăng cường: Random rotation (±10°), brightness/contrast jitter.

% Tập này dùng để đánh giá khả năng mở rộng trên dữ liệu lớn, unseen identities.

\section{Hàm mất mát biên góc: CosFace và ArcFace}

Để khởi tạo trọng số EdgeFace chất lượng cao trước khi tích hợp OrthoPQ, chúng tôi sử dụng CosFace và ArcFace – hai hàm mất mát biên góc phổ biến trong nhận diện khuôn mặt. Các hàm này cải thiện softmax tiêu chuẩn bằng cách thêm biên (margin) để tăng khoảng cách giữa lớp, giảm biến thiên nội lớp và tăng phân biệt ngoại lớp.

\subsection{CosFace: Large Margin Cosine Loss (Chi tiết toán học và đạo hàm)}
CosFace \cite{cosface} là một biến thể của softmax loss, được thiết kế để tăng cường phân biệt lớp bằng cách thêm biên cosine trực tiếp vào không gian cosine, sau khi chuẩn hóa L2 cả feature và weight. Phương pháp này tránh các vấn đề không đơn điệu \(non-monotonic\) của biên góc trong A-Softmax, và tập trung vào việc tạo biên cố định trong phân bố cosine.

\subsubsection{Công thức loss và chuẩn hóa}
Sau khi chuẩn hóa L2 cho feature \(x_i^*\) và weight \(W_j^*\) (với \(\|x_i\|_2 = 1\), \(\|W_j\|_2 = 1\)), cosine similarity trở thành:
\[
\cos \theta_{j,i} = W_j^T x_i
\]
Logit cho lớp đúng \(y_i\) được điều chỉnh bằng biên cosine \(m\):
\[
\psi_{y_i}(x_i) = \cos \theta_{y_i} - m
\]
với \(m \in [0, 1)\) là biên cosine (thường \(m = 0.2\)).

Hàm mất mát CosFace (LMCL) là:
\begin{equation}
\mathcal{L}_{\text{CosFace}} = \frac{1}{N} \sum_{i=1}^N -\log \frac{e^{s (\cos \theta_{y_i} - m)}}{e^{s (\cos \theta_{y_i} - m)} + \sum_{j \neq y_i} e^{s \cos \theta_{j,i}}}
\end{equation}
trong đó:
- \(N\): số mẫu huấn luyện.
- \(s > 0\): hệ số scale (thường \(s = 30-64\)) để kiểm soát bán kính hypersphere, đảm bảo \(\|x_i\| = s\) trong quá trình huấn luyện (bằng cách scale logit sau chuẩn hóa).

Biên \(m\) tạo ranh giới quyết định cố định trong không gian cosine: \(\cos \theta_1 \geq \cos \theta_2 + m\), tương đương biên hình học \(\sqrt{2}m\) giữa các lớp.

\subsubsection{Giới hạn lý thuyết cho \(m\) và \(s\)}
Để đảm bảo khả thi, \(m\) bị ràng buộc bởi số lớp \(C\) và chiều feature \(K\):
\begin{equation}
0 \leq m \leq 
\begin{cases} 
1 - \cos \frac{2\pi}{C} & \text{nếu } K = 2 \\
\frac{C}{C-1} & \text{nếu } K > 2, \, C \leq K+1 \\
\frac{C}{C-1} & \text{(giới hạn lỏng nếu } C > K+1\text{)}
\end{cases}
\end{equation}
Tương tự, \(s\) có giới hạn dưới để đảm bảo phân tách lớp:
\begin{equation}
s \geq \frac{C-1}{C} \ln \left( \frac{C-1}{P_W (1 - P_W)} \right)
\end{equation}
với \(P_W\): xác suất posterior tối thiểu mong đợi tại trung tâm lớp.

\subsubsection{Đạo hàm và lan truyền ngược}
Để tối ưu, chúng ta cần đạo hàm của \(\mathcal{L}\) theo \(x_i\) và \(W_j\). CosFace dựa trên softmax, nên đạo hàm logit \(\psi_k = s (\cos \theta_k - m \delta_{k,y_i})\) (với \(\delta\) là Kronecker delta).

Xác suất softmax:
\begin{equation}
p_k = \frac{e^{\psi_k}}{\sum_j e^{\psi_j}}
\end{equation}
Đạo hàm loss theo logit \(\psi_k\):
\begin{equation}
\frac{\partial \mathcal{L}}{\partial \psi_k} = p_k - \frac{1}{N} \sum_i \mathbb{I}(k = y_i)
\end{equation}
(trong đó \(\mathbb{I}\) là indicator function).

Đạo hàm theo cosine \(\cos \theta_k = W_k^T x_i\):
\begin{equation}
\frac{\partial \mathcal{L}}{\partial \cos \theta_k} = s \cdot \frac{\partial \mathcal{L}}{\partial \psi_k}
\end{equation}
Đạo hàm theo \(x_i\) (sau chuẩn hóa):
\begin{equation}
\frac{\partial \cos \theta_k}{\partial x_i} = W_k - (W_k^T x_i) x_i = W_k - \cos \theta_k \, x_i
\end{equation}
Tổng đạo hàm:
\begin{equation}
\frac{\partial \mathcal{L}}{\partial x_i} = \sum_k s \frac{\partial \mathcal{L}}{\partial \psi_k} (W_k - \cos \theta_k \, x_i)
\end{equation}
Tương tự cho \(W_k\):
\begin{equation}
\frac{\partial \mathcal{L}}{\partial W_k} = s \frac{\partial \mathcal{L}}{\partial \psi_k} (x_i - \cos \theta_k \, W_k)
\end{equation}
Các đạo hàm này đảm bảo gradient chảy mượt mà, tránh vanishing gradient ở biên lớn.

\subsubsection{So sánh ranh giới quyết định}
\begin{table}[htbp]
\centering
\caption{Ranh giới quyết định của CosFace so với các phương pháp khác}
\label{tab:cosface_boundary}
\begin{tabular}{|l|l|c|}
\hline
Phương pháp & Ranh giới nhị phân & Biên cosine \\
\hline
Softmax & \(\|W_1\| \cos \theta_1 = \|W_2\| \cos \theta_2\) & < 0 (chồng chéo) \\
NSL & \(\cos \theta_1 = \cos \theta_2\) & = 0 \\
A-Softmax & \(\cos(m \theta_1) = \cos \theta_2\) & Không đồng đều \\
\textbf{CosFace} & \(\cos \theta_1 - m \geq \cos \theta_2\) & Cố định \(m\) \\
\hline
\end{tabular}
\end{table}

\subsection{ArcFace: Additive Angular Margin Loss (Chi tiết toán học và đạo hàm)}
ArcFace \cite{arcface} mở rộng softmax bằng biên góc additive, hoạt động trực tiếp trên không gian góc để tạo phân tách hình học rõ ràng trên hypersphere.

\subsubsection{Công thức loss và chuẩn hóa}
Sau chuẩn hóa L2 (\(\|x_i\|_2 = 1\), \(\|W_j\|_2 = 1\)):
\[
\cos \theta_{j,i} = W_j^T x_i, \quad \theta_{j,i} = \arccos(\cos \theta_{j,i})
\]
Logit cho lớp đúng:
\begin{equation}
\psi_{y_i}(x_i) = \cos(\theta_{y_i} + m)
\end{equation}
với \(m > 0\) là biên góc (thường \(m = 0.5\)).

Hàm mất mát ArcFace:
\begin{equation}
\mathcal{L}_{\text{ArcFace}} = \frac{1}{N} \sum_{i=1}^N -\log \frac{e^{s \cos(\theta_{y_i} + m)}}{e^{s \cos(\theta_{y_i} + m)} + \sum_{j \neq y_i} e^{s \cos \theta_{j,i}}}
\end{equation}
Hệ số \(s\) scale logit để kiểm soát độ lớn gradient (thường \(s = 64\)).

Biên \(m\) tạo phân tách geodesic cố định trên hypersphere, tăng khoảng cách góc giữa lớp.

\subsubsection{Giới hạn lý thuyết cho \(m\) và \(s\)}
\(m\) bị ràng buộc để tránh \(\theta + m > \pi\):
\begin{equation}
0 < m \leq \pi - \max \theta_{y_i}
\end{equation}
Thực tế, \(m \leq 0.8\) cho \(C\) lớn. \(s\) tương tự CosFace, nhưng ArcFace nhạy cảm hơn với \(s\) do non-monotonic của \(\cos(\theta + m)\).

\subsubsection{Đạo hàm và lan truyền ngược}
Sử dụng chain rule từ \(\psi_k = s \cos(\theta_k + m \delta_{k,y_i})\).

Xác suất \(p_k\) như CosFace. Đạo hàm loss theo \(\psi_k\) giống trên.

Đạo hàm theo góc \(\theta_k\):
\begin{equation}
\frac{\partial \psi_k}{\partial \theta_k} = -s \sin(\theta_k + m \delta_{k,y_i})
\end{equation}
Đạo hàm theo cosine:
\begin{equation}
\frac{\partial \theta_k}{\partial \cos \theta_k} = -\frac{1}{\sqrt{1 - \cos^2 \theta_k}} = -\frac{1}{\sin \theta_k}
\end{equation}
Tổng đạo hàm theo \(x_i\):
\begin{equation}
\frac{\partial \mathcal{L}}{\partial x_i} = \sum_k \frac{\partial \mathcal{L}}{\partial \psi_k} \cdot \left( -s \sin(\theta_k + m \delta) \cdot \left( -\frac{1}{\sin \theta_k} \right) \cdot (W_k - \cos \theta_k x_i) \right)
\end{equation}
Tương tự cho \(W_k\), nhưng phức tạp hơn do \(\sin\) term, đòi hỏi clipping gradient để ổn định.

ArcFace gradient lớn hơn ở biên, giúp hội tụ nhanh nhưng dễ overfit nếu không có regularization.

\subsubsection{So sánh với CosFace}
\begin{table}[htbp]
\centering
\caption{So sánh CosFace và ArcFace}
\label{tab:cos_arc_compare}
\begin{tabular}{|l|c|c|}
\hline
Tiêu chí & CosFace & ArcFace \\
\hline
Biên & Cosine (\( \cos \theta - m \)) & Angular (\( \cos(\theta + m) \)) \\
Đơn điệu & Có (monotonic) & Không (non-monotonic) \\
Đạo hàm & Ổn định & Lớn hơn, cần clip \\
Unseen identities & Tốt (cô đặc) & Tốt hơn (phân tách góc) \\
\hline
\end{tabular}
\end{table}

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.8\textwidth]{images/cos_arc_embedding.png}
%     \caption{Visualization phân bố embedding trên hypersphere với CosFace (trái) và ArcFace (phải). ArcFace tạo biên góc rõ ràng hơn.}
%     \label{fig:cos_arc_embedding}
% \end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{images/cos_arc_embedding.png}
    \caption{
        So sánh phân bố embedding giữa \textbf{CosFace} và \textbf{ArcFace}. 
        (a) Với CosFace, các vector được chuẩn hoá lên hypersphere nhưng biên dạng giữa các lớp 
        chưa tách biệt rõ ràng do sử dụng margin dạng cosine. 
        (b) Với ArcFace, các embedding được ép buộc tạo \emph{angular margin} trực tiếp trên không gian góc, 
        giúp các cụm dữ liệu phân tách tốt hơn trên hypersphere. 
        Quan sát cho thấy ArcFace tạo ra biên dạng phân bố đều, rõ ràng và ổn định hơn CosFace.
    }
    \label{fig:cosface_arcface}
\end{figure}

% \subsection{CosFace: Large Margin Cosine Loss}
% CosFace \cite{cosface} thêm biên cosine vào logit:

% Công thức logit cho lớp đúng $y_i$:
% \[
% \logit_{y_i} = \|x_i\| \|W_{y_i}\| (\cos \theta_{y_i} - m)
% \]
% với $m$ là biên cosine (thường 0.2-0.35), $\cos \theta_{y_i} = \frac{x_i^T W_{y_i}}{\|x_i\| \|W_{y_i}\|}$.

% Hàm mất mát:
% \[
% L = -\frac{1}{N} \sum_{i=1}^N \log \frac{e^{s (\cos \theta_{y_i} - m)}}{e^{s (\cos \theta_{y_i} - m)} + \sum_{j \neq y_i} e^{s \cos \theta_j}}
% \]
% với $s$ là scale (thường 30-64) để ổn định gradient.

% Lý do sử dụng: CosFace ép embedding tụ về trung tâm lớp, dễ lượng tử hóa hơn. Chúng tôi dùng m=0.2, s=30 cho pretrain EdgeFace.

% \subsection{ArcFace: Additive Angular Margin Loss}
% ArcFace \cite{arcface} thêm biên góc:
% \[
% \logit_{y_i} = \|x_i\| \|W_{y_i}\| \cos (\theta_{y_i} + m)
% \]

% Hàm mất mát tương tự CosFace nhưng biên trên góc $\theta$ (m=0.5 thường).

% So sánh: ArcFace tạo biên hình học nghiêm ngặt hơn, tốt cho unseen identities; CosFace linh hoạt hơn với cosine trực tiếp.

% Chúng tôi pretrain EdgeFace với cả hai (m=0.5/s=30 cho ArcFace, m=0.2/s=30 cho CosFace) để so sánh.

% Hình \ref{fig:cos_arc_comparison} minh họa phân bố embedding.

% \begin{figure}[htbp]
%     \centering
%     % \includegraphics[width=0.8\textwidth]{images/cosface_arcface.png}
%     \caption{So sánh phân bố embedding với CosFace và ArcFace trên hypersphere.}
%     \label{fig:cos_arc_comparison}
% \end{figure}

\section{Thay thế backbone bằng EdgeFace và các biến thể}

EdgeFace \cite{george2024edgeface} là backbone chính, dựa trên EdgeNeXt nhưng tối ưu cho face recognition với LoRaLin và classification head.

\subsection{Cấu trúc EdgeFace}
- Dựa trên EdgeNeXt: 4 stages với Conv Encoder (depth-wise conv + point-wise) và SDTA (channel-wise attention).
- Thay linear layers bằng LoRaLin với gamma để giảm params/FLOPs.
- Input: 112x112 (tối ưu cho face).
- Output: 512-dim embedding sau AdaptiveAvgPool + LayerNorm + LoRaLin.

\subsubsection{Mô tả toán học của LoRaLin}
LoRaLin (Low-Rank Linear) là kỹ thuật phân tích ma trận trọng số full-rank thành low-rank để giảm tham số và FLOPs, dựa trên giả thuyết rằng ma trận trọng số học được có rank thấp (SVD approximation).

Cho lớp linear chuẩn \(W \in \mathbb{R}^{M \times N}\), output \(y = W x + b\). LoRaLin thay thế:
\begin{equation}
W \approx U V^T
\end{equation}
với \(U \in \mathbb{R}^{M \times r}\), \(V \in \mathbb{R}^{N \times r}\), \(r \ll \min(M,N)\) là rank.

Rank \(r\) được chọn:
\begin{equation}
r = \max\left(2, \gamma \cdot \min(M,N)\right)
\end{equation}
\(\gamma \in (0,1)\) là rank-ratio (thường 0.6).

Tổng tham số giảm từ \(MN\) xuống \(r(M + N)\), FLOPs từ \(2MN\) xuống \(2r(M + N)\).

Triển khai: Hai lớp linear liên tiếp:
\begin{equation}
y = (V^T x) \cdot U + b  \quad (\text{hoặc } U (V^T x) + b)
\end{equation}
Gradient lan truyền: \(\frac{\partial y}{\partial x} = V U^T\).

Lý thuyết: Dựa trên Eckart-Young theorem, low-rank approx giữ 99\% variance nếu \(r\) đủ lớn, giảm overfitting trong edge devices.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/lora_svd.png}
    \caption{Phân tích SVD cho LoRaLin: Giữ top-r singular values.}
    \label{fig:lora_svd}
\end{figure}

\subsection{Các biến thể EdgeFace sử dụng}
Chúng tôi đánh giá nhiều variants để tìm tối ưu:

\begin{table}[htbp]
\centering
\caption{So sánh các biến thể EdgeFace}
% \label{tab:edgeface_variants}
\begin{tabular}{|l|c|c|c|c|}
\hline
Biến thể & Params (M) & FLOPs (M) & Gamma & Ghi chú \\
\hline
EdgeFace-Base & ~5.6 & ~1000 & N/A & Phiên bản lớn, dùng cho benchmark \\
EdgeFace-S-Gamma-0.5 & ~2.5 & ~500 & 0.5 & S variant, gamma giảm params 20\% \\
EdgeFace-XS-Q & ~1.77 & ~150 & 0.6 & XS quantized, tối ưu edge \\
EdgeFace-XXS-Q & ~1.3 & ~100 & 0.6 & XXS quantized, nhẹ nhất \\
EdgeFace-XSS & ~1.5 & ~120 & 0.6 & Variant custom, cân bằng XS/XXS \\
\hline
\end{tabular}
\end{table}

- \textbf{EdgeFace-XS-Gamma-0.6}: XS với LoRaLin gamma=0.6, giảm 20\% params/FLOPs, duy trì accuracy (LFW 99.73\%).
- Lý do chọn: Gamma=0.6 là sweet spot từ experiments (Hình 3 trong \cite{george2024edgeface}), cân bằng nén và performance.
- Quantized variants (Q): Sử dụng post-training quantization (INT8) để giảm thêm memory.

Tất cả variants được pretrain trên WebFace4M/12M trước khi integrate OPQN.


\subsubsection{Phân tích lý thuyết: Tại sao \(\gamma = 0.6\) tối ưu?}
Từ paper EdgeFace \cite{george2024edgeface}, \(\gamma = 0.6\) là điểm cân bằng giữa nén và performance, dựa trên SVD analysis.

Lý thuyết: Ma trận \(W\) có singular values \(\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_r\). Low-rank approx lỗi:
\begin{equation}
\|W - U_r V_r^T\|_F^2 = \sum_{k=r+1}^{\min(M,N)} \sigma_k^2
\end{equation}
\(\gamma = 0.6\) giữ ~95\% variance (từ experiments: accuracy drop <0.5\% trên LFW), giảm params 40\% so với full-rank.

Trong edge devices, \(\gamma = 0.6\) giảm FLOPs bậc tuyến tính, tránh underfitting (gamma <0.4) hoặc overfit (gamma >0.8).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{images/gamma_curve.png}
    \caption{Accuracy vs. Gamma trên IJB-C: Peak tại 0.6 (từ Fig.3, George et al., 2024).}
    \label{fig:gamma_curve}
\end{figure}

\section{Các chiến lược huấn luyện EdgeFace trong OPQN}

Để tối ưu tích hợp, chúng tôi áp dụng 4 chiến lược, đánh giá trên tất cả variants EdgeFace.

\subsection{Chiến lược 1: Freeze Backbone}
- Giữ cố định toàn bộ EdgeFace trừ head.
- Chỉ train OrthoPQ và classifier.
- Ưu: Giảm overfitting, huấn luyện nhanh (5-7 giờ/Kaggle).
- Nhược: Có thể thiếu adaption đặc trưng cho lượng tử hóa.
- Implement: model.backbone.requires\_grad = False.

% \subsubsection{Pseudo-code cho Chiến lược 1: Freeze Backbone}
\begin{algorithm}[htbp]
\caption{Freeze Backbone trong OPQN + EdgeFace}
\begin{algorithmic}[1]
\Require Pretrained EdgeFace, dataset $D$, epochs $E$
\Ensure Trained model
\State model.backbone.requires\_grad $\gets$ \texttt{False} \Comment{Freeze}
\State optimizer $\gets$ SGD(model.pq\_layers.parameters(), lr=0.01)
\For{$e = 1$ to $E$}
    \For{batch $\in D$}
        \State $x \gets$ backbone(batch.img) \Comment{Forward frozen}
        \State codes $\gets$ ortho\_pq(x)
        \State loss $\gets L_{\text{clf}}(\text{codes}) + 0.1\,L_{\text{ent}}$
        \State loss.backward()
        \State optimizer.step()
        \State optimizer.zero\_grad()
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Chiến lược 2: Unfreeze Backbone}
- Fine-tune toàn bộ EdgeFace + OrthoPQ.
- LR backbone thấp hơn (1e-5 vs 1e-3 cho PQ).
- Ưu: Học đặc trưng phù hợp hơn, cải thiện mAP 2-5\%.
- Nhược: Rủi ro overfitting, thời gian dài hơn (8-10 giờ).
- Regularization: Weight decay 1e-4, dropout 0.1.

% \subsubsection{Pseudo-code cho Chiến lược 2: Unfreeze Backbone}
\begin{algorithm}[htbp]
\caption{Unfreeze Backbone (End-to-End)}
\begin{algorithmic}[1]
\Require Pretrained EdgeFace, dataset $D$, epochs $E$
\Ensure Fine-tuned model
\State model.backbone.requires\_grad $\gets$ \texttt{True}
\State opt\_back $\gets$ AdamW(backbone.parameters(), lr=1e-5)
\State opt\_pq $\gets$ SGD(pq\_layers.parameters(), lr=0.001)
\For{$e = 1$ to $E$}
    \For{batch $\in D$}
        \State $x \gets$ backbone(batch.img)
        \State codes $\gets$ ortho\_pq(x)
        \State loss $\gets L_{\text{clf}}(\text{codes}) + 0.1\,L_{\text{ent}}$
        \State loss.backward()
        \State opt\_back.step()
        \State opt\_pq.step()
        \State opt\_back.zero\_grad()
        \State opt\_pq.zero\_grad()
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Chiến lược 3: Pretrain với CosFace + OrthoPQ}
- Pretrain EdgeFace với CosFace trên WebFace.
- Sau đó integrate OrthoPQ, fine-tune end-to-end.
- CosFace ép embedding cô đặc → dễ lượng tử hóa.
- Params: s=30, m=0.2, optimizer AdamW + poly decay.

% \subsubsection{Pseudo-code cho Chiến lược 3: Pretrain với CosFace + tích hợp OPQN}
\begin{algorithm}[htbp]
\caption{Pretrain EdgeFace bằng CosFace rồi fine-tune với OrthoPQ}
\label{alg:cosface_pretrain}
\begin{algorithmic}[1]
\Require Dataset lớn $D_{\text{pre}}$, dataset mục tiêu $D_{\text{target}}$, số epoch pretrain $E_1$, số epoch fine-tune $E_2$
\Ensure Backbone được pretrain bằng CosFace và mô-đun OrthoPQ hội tụ

\Statex \textbf{// Giai đoạn 1: Pretrain EdgeFace với CosFace}
\State model $\gets$ EdgeFace(variant) \Comment{Base/XS/XXS/...}
\State model.classifier $\gets$ Linear(512, num\_classes\_pre)
\State optimizer $\gets$ AdamW(model.parameters(), lr=1e{-}3, weight\_decay=5e{-}4)
\State scheduler $\gets$ CosineAnnealingLR + Warmup(5 epochs)
\For{$e = 1$ to $E_1$}
    \For{batch $\in D_{\text{pre}}$}
        \State img, label $\gets$ batch
        \State $x \gets$ model.backbone(img)
        \State logits $\gets$ model.classifier(x)
        \State loss $\gets$ \text{CosFace}( \text{logits}, \text{label},\, s=30,\, m=0.2 )
        \State loss.backward()
        \State optimizer.step()
        \State optimizer.zero\_grad()
    \EndFor
    \State scheduler.step()
\EndFor
\State \textbf{Save} backbone: \texttt{edgeface\_cosface.pth}

\Statex \textbf{// Giai đoạn 2: Tích hợp OrthoPQ và fine-tune end-to-end}
\State Load pretrained backbone vào mô hình OPQN
\State model.pq\_module $\gets$ OrthoPQ(D=512, M=8, K=64)
\State optimizer\_back $\gets$ AdamW(model.backbone.parameters(), lr=1e{-}5)
\State optimizer\_pq $\gets$ SGD(model.pq\_module.parameters(), lr=0.01, momentum=0.9)

\For{$e = 1$ to $E_2$}
    \For{batch $\in D_{\text{target}}$}
        \State $x \gets$ model.backbone(batch.img)
        \State $s, p, h \gets$ model.pq\_module(x)
        \State $L_{\text{clf}} \gets \frac{1}{2}(L_x(x) + L_s(s))$
        \State $L_{\text{ent}} \gets -\sum p\log p$
        \State loss $\gets L_{\text{clf}} + 0.1 L_{\text{ent}}$
        \State loss.backward()
        \State optimizer\_back.step()
        \State optimizer\_pq.step()
        \State optimizer\_back.zero\_grad()
        \State optimizer\_pq.zero\_grad()
    \EndFor
    \If{val\_mAP không cải thiện trong 10 epoch}
        \State \textbf{Early stopping}
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Chiến lược 4: Pretrain với ArcFace + OrthoPQ}
- Tương tự nhưng dùng ArcFace (m=0.5).
- ArcFace tạo biên góc lớn → tốt cho unseen.
- So sánh: ArcFace thường vượt CosFace 1-2\% trên VGGFace2 unseen.

Mỗi chiến lược chạy với batch=256, 300 epochs, early stopping nếu val loss không giảm 10 epochs.


% \subsubsection{Pseudo-code cho Chiến lược 4: Pretrain với ArcFace + tích hợp OPQN}
\begin{algorithm}[htbp]
\caption{Pretrain EdgeFace bằng ArcFace rồi fine-tune với OrthoPQ}
\label{alg:arcface_pretrain}
\begin{algorithmic}[1]
\Require Dataset lớn $D_{\text{pre}}$, dataset mục tiêu $D_{\text{target}}$, số epoch pretrain $E_1$, số epoch fine-tune $E_2$
\Ensure Mô hình cuối cùng với backbone đã được pretrain ArcFace

\Statex \textbf{// Giai đoạn 1: Pretrain EdgeFace với ArcFace}
\State model $\gets$ EdgeFace(variant)
\State model.classifier $\gets$ Linear(512, num\_classes\_pre)
\State optimizer $\gets$ AdamW(model.parameters(), lr=1e{-3}, weight\_decay=5e{-4})
\State scheduler $\gets$ \text{CosineAnnealingLR + Warmup}(5\text{ epochs})
\For{$e = 1$ \textbf{to} $E_1$}
    \For{batch $\in D_{\text{pre}}$}
        \State img, label $\gets$ batch
        \State x $\gets$ model.backbone(img)
        \State logits $\gets$ model.classifier(x)
        \State loss $\gets$ \text{ArcFace}(logits, label, $s=64$, $m=0.5$)
        \State loss.backward()
        \State optimizer.step()
        \State optimizer.zero\_grad()
    \EndFor
    \State scheduler.step()
\EndFor
\State \textbf{Save} pretrained backbone: \texttt{edgeface\_arcface.pth}

\Statex \textbf{// Giai đoạn 2: Tích hợp OrthoPQ (giống chiến lược 3)}
\State \textbf{Load} \texttt{edgeface\_arcface.pth} vào mô hình OPQN
\State model.pq\_module $\gets$ OrthoPQ($D=512$, $M=8$, $K=64$)
\State optimizer\_back $\gets$ AdamW(model.backbone.parameters(), lr=5e{-6})
\State optimizer\_pq   $\gets$ SGD(model.pq\_module.parameters(), lr=0.01)

\For{$e = 1$ \textbf{to} $E_2$}
    \For{batch $\in D_{\text{target}}$}
        \State x $\gets$ model.backbone(batch.img)
        \State s, p, h $\gets$ model.pq\_module(x)
        \State loss $\gets L_{\text{clf}}(x, s) + 0.1\, L_{\text{ent}}(p)$
        \State loss.backward()
        \State optimizer\_back.step()
        \State optimizer\_pq.step()
        \State optimizer\_back.zero\_grad()
        \State optimizer\_pq.zero\_grad()
    \EndFor
    \If{\text{val\_mAP plateau}}
        \State Giảm learning rate xuống 0.1×
    \EndIf
\EndFor

\end{algorithmic}
\end{algorithm}

\section{Quy trình huấn luyện chi tiết}

\subsection{Giai đoạn 1: Pretrain EdgeFace (nếu áp dụng)}
- Dataset: WebFace4M (4M ảnh, 260K identities) hoặc MS1MV2.
- Augmentation: RandomResizedCrop, ColorJitter, RandAug (magnitude=9).
- Loss: CosFace/ArcFace + label smoothing 0.1.
- Optimizer: AdamW (beta1=0.9, beta2=0.999), lr=1e-3 base, cosine scheduler + warmup 5 epochs.
- Distributed training: DDP trên 2 GPU.
- Thời gian: 20-30 epochs cho convergence.

\subsection{Giai đoạn 2: Tích hợp và fine-tune với OPQN}
- Sinh codewords OrthoPQ: DCT-II, M=8, K=64 cho 48 bit.
- Loss: $L_{clf}$ (subspace classification) + 0.1 $L_{ent}$ (entropy reg).
- Optimizer: SGD momentum 0.9, lr=0.1, ReduceLROnPlateau (factor=0.1, patience=5).
- Monitoring: Val mAP trên FaceScrub subset mỗi 10 epochs.
- Partial FC: Sample 10\% classes/batch cho large identities (VGGFace2).

\section{Giai đoạn truy xuất và đánh giá}

- Database: Hard quantization → store indices B (N x M).
- Query: Soft quantization → compute AQD via LUT.
- Top-k retrieval: Argmax sum p\_qm,b\_im.
- Đánh giá: mAP, P@K (10-100), ms/query trên Kaggle CPU/GPU.
- So sánh: Với OPQN-ResNet20 baseline.

\section{Tổng kết chương}

Chương này đã trình bày sâu phương pháp đề xuất, tập trung kỹ thuật: CosFace/ArcFace cho pretrain, các variants EdgeFace (XS gamma 0.6,...), 4 chiến lược huấn luyện, tiền xử lý dữ liệu (FaceScrub 32/112, VGGFace2). Tổng cộng, các cải tiến giảm 92\% params, phù hợp edge devices, đặt nền tảng cho thực nghiệm chương 4.






% %\chapter{Hướng dẫn sử dụng template}
% \chapter{Phương pháp}
% \label{Chapter3}

% \section{Mạng lượng tử hoá tích trực chuẩn cho truy xuất ảnh khuôn mặt quy mô lớn}
% \subsection{Tổng quan về mạng lượng tử hoá tích trực chuẩn}
% Mạng lượng tử hoá tích trực chuẩn là một mạng nơ-ron sử dụng lượng tử hoá với ràng buộc vuông góc, sử dụng bộ mã được định nghĩa trước nhằm tăng độ phân biệt và giảm sự dư thừa giữa các thông tin đặc trưng với nhau, giải quyết các thách thức về biến đổi nội lớp như tư thế, ánh sáng, biểu cảm. Khả năng tổng quá hoá cao, phù hợp với nhu cầu truy xuất các danh tính chưa từng thấy.

% \begin{figure}[htbp] % hoặc [htbp]
%     \centering
%     \includegraphics[width=0.8\textwidth]{images/opqn_model.png} 
%     \caption{Mô hình lượng tử hoá tích trực chuẩn}
%     \label{fig:opqn_rmodel_types}
% \end{figure}

% Các thành phần chính và kiến trúc của mạng lượng tử hoá tích trực chuẩn bao gồm các thành phần cốt lõi như sau: Mạng xương sống, lượng tử hoá mềm thông qua khử tương quan đặc trưng - xác suất, sinh mã từ trực chuẩn, hàm mất mát phân loại kết hợp theo từng không gian con, tối thiểu hoá độ cô đặc cho việc gán mã one-hot, quá trình học và tối ưu hoá và khoảng cách bất đối xứng trong truy xuất.
% \subsection{Các ký hiệu và ký pháp}
% Trong mô hình OPQN, các ký hiệu và ký pháp được định nghĩa để mô tả rõ ràng các thành phần dữ liệu, đặc trưng, và hàm mất mát. Bảng \ref{tab:terms_part1} và \ref{tab:terms_part2} trình bày chi tiết các ký hiệu này, được sử dụng xuyên suốt phần phương pháp để giải thích quy trình lượng tử hóa và tối ưu hóa.

% \begin{table}[h!]
%     \centering
%     \begin{tabular}{|c|p{3cm}|p{6cm}|}
%         \hline
%         \textbf{Ký hiệu} & \textbf{Ký pháp} & \textbf{Mô tả} \\ \hline
%         $I_i$ & $\{I_i\}_{i=1}^N$ & Tập hợp $N$ hình ảnh khuôn mặt đầu vào. \\ \hline
%         $y_i$ & $y \in \mathbb{R}^N$ & Nhãn danh tính tương ứng với hình ảnh $I_i$. \\ \hline
%         $x_i$ & $x_i = f(\Theta, I_i) \in \mathbb{R}^D$ & Đặc trưng nút cổ chai được trích xuất từ hình ảnh $I_i$ bởi mạng xương sống với tham số $\Theta$, có chiều $D$. \\ \hline
%         $x_{im}$ & $x_{im} \in \mathbb{R}^d$ & Vector con thứ $m$ của ảnh đặc trưng $x_i$, với $d = D/M$ và $m = 1, \dots, M$. \\ \hline
%         $M$ & $M$ & Số lượng vectơ con mà đặc trưng $x_i$ được chia thành. \\ \hline
%         $d$ & $d = D/M$ & Chiều của mỗi vector con $x_{im}$. \\ \hline
%         $C$ & $C = [C_1, \dots, C_M]$ & Tập hợp $M$ bộ mã, mỗi bộ mã $C_m \in \mathbb{R}^{d \times K}$ chứa $K$ từ mã trực chuẩn. \\ \hline
%         $C_{mk}$ & $C_{mk} \in \mathbb{R}^d$ & Từ mã thứ $k$ trong bộ mã $C_m$. \\ \hline
        % $F$ & $F = [F_1, \dots, F_M]$ & Tập hợp ma trận tham số của các lớp tuyến tính, với $F_m \in \mathbb{R}^{d \times K}$. \\ \hline
        % $F_{mk}$ & $F_{mk} \in \mathbb{R}^d$ & Vectơ tham số thứ $k$ trong ma trận $F_m$. \\ \hline
        % $p_{im}$ & $p_{im} = [p_{im,1}, \dots, p_{im,K}] \in \mathbb{R}^K$ & Vector xác suất của vector con $x_{im}$, được tính qua softmax: $p_{im,k} = \frac{e^{x_{im}^T F_{mk}}}{\sum_{j=1}^K e^{x_{im}^T F_{mj}}}$. \\ \hline
        % $s_{im}$ & $s_{im} = \sum_{k=1}^K p_{im,k} \cdot C_{mk}$ & Lượng tử hóa mềm của vectơ con $x_{im}$. \\ \hline
        % $h_{im}$ & $h_{im} = C_{m k^*}$, $k^* = \arg\max_k p_{im,k}$ & Lượng tử hóa cứng của vectơ con $x_{im}$. \\ \hline
%     \end{tabular}
%     \caption{Phần 1: Ký hiệu và ký pháp (Dữ liệu và đặc trưng)}
%     \label{tab:terms_part1}
% \end{table}

% \begin{table}[h!]
%     \centering
%     \begin{tabular}{|c|p{6cm}|p{5cm}|}
%         \hline
%         \textbf{Ký hiệu} & \textbf{Ký pháp} & \textbf{Mô tả} \\ \hline
%         $W$ & $W = [W_1, \dots, W_M]$ & Tập hợp trọng số của các bộ phân lớp theo không gian con, với $W_m \in \mathbb{R}^{d \times C}$. \\ \hline
%         $W_{mc}$ & $W_{mc} \in \mathbb{R}^d$ & Trọng số của lớp $c$ trong bộ phân lớp $W_m$. \\ \hline
%         $L_x$ & $L_x = \sum_{i=1}^N \sum_{m=1}^M -\log \frac{e^{r (\cos \theta_{y_i, x_{im}} - u)}}{e^{r (\cos \theta_{y_i, x_{im}} - u)} + \sum_{j \neq y_i} e^{r \cos \theta_{j, x_{im}}}}$ & Hàm mất mát phân lớp cho đặc trưng gốc $x_{im}$ dựa trên softmax với biên góc $u$ và tham số $r$. \\ \hline
%         $L_s$ & Tương tự $L_x$ & Hàm mất mát phân lớp cho lượng tử hóa mềm $s_{im}$. \\ \hline
%         $L_{clf}$ & $L_{clf} = \frac{1}{2MN} (L_x + L_s)$ & Hàm mất mát phân lớp liên hợp theo không gian con. \\ \hline
%         $L_{ent}$ & $L_{ent} = -\frac{1}{MN} \sum_{i=1}^N \sum_{m=1}^M \sum_{k=1}^K p_{im,k} \log p_{im,k}$ & Hàm mất mát entropy để khuyến khích $p_{im}$ gần với one-hot. \\ \hline
%         $L$ & $L = L_{clf} + \lambda L_{ent}$ & Hàm mất mát tổng, với $\lambda$ là trọng số điều chỉnh. \\ \hline
%         $\Theta$ & $\Theta$ & Tham số của mạng xương sống. \\ \hline
%         $A$ & $A_{ij} = \cos\left[j\pi \cdot \frac{i + \frac{1}{2}}{d}\right]$ & Ma trận cơ sở trực chuẩn được sinh bởi DCT-II cho các từ mã. \\ \hline
%         $K$ & $K \leq d$ & Số lượng các từ mã trong mỗi bộ mã $C_m$. \\ \hline
%         $u$ & $u$ & Biên góc trong hàm mất mát phân lớp. \\ \hline
%         $r$ & $r$ & Tham số điều chỉnh trong hàm mất mát phân lớp. \\ \hline
%     \end{tabular}
%     \caption{Phần 2: Ký hiệu và ký pháp (Hàm mất mát và tham số)}
%     \label{tab:terms_part2}
% \end{table}


% Các ký hiệu này sẽ được áp dụng trong các phân đoạn sau để mô tả chi tiết quy trình lượng tử hóa mềm, sinh từ mã trực chuẩn, huấn luyện và truy xuất mô hình OPQN.

% \subsection{Lượng tử hoá mềm thông qua khử tương quan đặc trưng - xác suất}

% \subsubsection{Lượng tử hoá mềm và Lượng tử hoá cứng}
% Lượng tử hoá trong học máy và thị giác máy tính là quá trình ánh xạ một vectơ đặc trưng liên tục về một tập hữu hạn các từ mã trong bộ mã. Lượng tử hoá được chia thành hai loại: Lượng tử hoá cứng và lượng tử hoá mềm. Trong đó, lượng tử hoá cứng ánh xạ đặc trưng vào một từ mã duy nhất ở gần nhất, lượng tử hoá mềm ánh xạ mỗi  đặc trưng vào tổ hợp tuyến tính của nhiều từ mã, với trọng số là xác suất.

% Mặc dù lượng tử hoá cứng có độ phức tạp tính toán nhanh hơn so với lượng tử hoá mềm, nhưng lại không khả vi vì hàm chọn từ mã gây gián đoạn tính toán độ dốc, ảnh hưởng đến quá trình lan truyền ngược. Thêm vào đó, độ mất mát thông tin của lượng tử hoá cứng cao, mỗi vectơ chỉ ánh xạ đến một từ mã gần nhất. Vì thế cho nên, nghiên cứu không dùng lượng tử hoá cứng trong việc lượng tử hoá ảnh đầu vào để huấn luyện mô hình. Thay vào đó, tận dụng tốc độ tính toán nhanh của chúng cho việc lượng tử hoá hàng triệu ảnh lưu cơ sở dữ liệu, phục vụ quá trình truy xuất thông tin diễn ra với tốc độc cao và giảm chi phí tính toán.

% Ngược lại, lượng tử hoá mềm phục vụ mô hình trong việc huấn luyện đầu-cuối nhờ tính khả vi của hàm trung bình mũ, độ dốc được giữ liên tụ. Độ mất mát thông tin thấp hơn do lượng tử hoá mềm là một tổ hợp tuyến tính có trọng số là xác xuất trên tập hữu hạn các từ mã, tránh mất mát các thông tin đặc trưng quan trọng, đặc biệt là các đặc trưng của biến thể nội lớp.

% % Khử tương quan đặc trưng-xác suất vs Các phương pháp lượng tử hoá truyền thống 
% Bên cạnh sự phân loại trên, nghiên cứu không chỉ dừng ở việc so sánh giữa lượng tử hoá cứng và mềm, mà còn tập trung vào khử tương quan đặc trưng và sử dụng xác suất trong ánh xạ, thay thế các phương pháp lượng tử hoá truyền thống.

% \subsubsection{Vấn đề của lượng tử hoá tích} 
% Trong lượng tử hoá tích (PQ) truyền thống, vectơ đặc trưng $x \in \mathbb{R}^D$ được chia thành nhiều vectơ con $x = [x_1, x_2,...,x_M]$, $x \in \mathbb{R}^{D/M}$, $x_{i,m} = [x_{i,1}, x_{i,2},...,x_{1,d}]$. Tuy nhiên, có ba hạn chế mà phép lượng tử hoá tích gặp phải: Tương quan đặc trưng chưa được xử lý, lượng tử hoá gây mất mát thông tin ngữ nghĩa, độ chính xác của truy xuất giảm đối do sai số lượng tử hoá. 

% Thứ nhất, trong nhiều đặc trưng từ CNN, các chiều thường tương quan mạnh, thông tin về một yếu tố như ánh sáng, kiểu dáng, etc.. có thể trải trên nhiều chiều, nhưng việc chia vectơ đặc trưng $x$ thành nhiều vectơ con $x_m$ và lượng tự hoá độc lập chúng với từng từ mã $C_m$, điều này ngầm giả định rằng các vectơ con là tương đối độc lập. Khi biểu diễn tương quan qua ma trận hiệp phương sai $\Sigma = \mathbb{E}[(x-\mu)(x-\mu)^T]$, nếu $\Sigma$ có nhiều phần tử ngoài đường chéo lớn, nghĩa là các chiều phụ thuộc nhau, khi chia theo chỉ số, các không gian con thường không trùng với các trục chính của phân phối, tức là các thành phần có phương sai lớn và phụ thuộc lẫn nhau có thể nằm dàn trải qua nhiều không gian con. Hệ quả rằng các bộ mã độc lập cho từng không gian con không thể mô tả tốt các mối liên hệ chéo giữa các chiều, làm sai số lượng tử lớn hơn so với việc lượng tử hoá chung -tối ưu hoá toàn cục, bên cạnh đó sai số khôi phục tăng, làm giảm chất lượng truy hồi, đặc biệt với dữ liệu có cấu trúc ngữ nghĩa mạnh. 

% Thứ hai, mất mát thông tin khi chia các vectơ con, nếu có một thông tin ngữ nghĩa nào đó phụ thuộc vào sự phối hợp của nhiều chiều nằm ở các vectơ con khác nhau, thì khi cắt ra và lượng tử hoá độc lập chúng, ta sẽ phá vỡ mối quan hệ đó, gây mất mát thông tin ngữ nghĩa. Hệ quả của việc chia vectơ đặc trưng thành các vectơ con và lượng tử hoá chúng theo phương pháp lượng tử hoá tích, các khác biệt tinh tế giữa các mẫu ảnh sẽ bị làm mờ, và các bộ mã dù có tổ hợp các trung tâm mã trong bộ mã lớn, nhưng không thể biểu diễn chính xác quan hệ chéo.

% Thứ ba, độ chính xác truy hồi giảm do sai số lượng tử hoá, trong phương pháp tiìm kiếm láng giềng gần nhất, ta quan tâm đến xếp hạng khoảng cách giữa truy vấn $q$ và các vectơ dữ liệu $x$. Với lượng tử hoá tích, ta đo khoảng cách $\|q - x\|^2 \;\approx\; \sum_{m=1}^M \|q_m - c_{m,k_m}\|^2$, nhưng nếu $\hat{x}$ ($x$ sau khi lượng tử hoá) khác xa $x$ do sai số lượng tử hoá lớn, thì khoảng cách tính bị sai lệch, dẫn đến thứ tự xếp hạng truy xuất thay đổi.

% \subsubsection{Khử tương quan đặc trưng-xác suất}
% Để khắc phục các hạn chế nêu trên của phương pháp lượng tử hoá tích, bài báo OPQN đề xuất cơ chế khử tương quan đặc trưng - xác suất.

% Thay vì ánh xạ trực tiếp vectơ con vào các từ mã bằng khoảng cách Ơ-clid như trong lượng tử hoá tích, OPQN chèn thêm một tầng tuyến tính. Với mỗi vectơ con $x_{im}$, tầng này chiếu đặc trưng sang một không gian mới, rồi tính điểm tương ứng cho từng từ mã. Sau đó, các điểm này đi qua hàm trung bình mũ để tạo thành phân phối xác suất gán cho các từ mã. Cốt lõi của cơ chế khử tương quan nằm ở chỗ đặc trưng không còn gắn trực tiếp với các vectơ con độc lập, mà được ánh xạ sang một không gian xác suất. Công thức được tính như sau:


% \begin{equation}
% p_{im,k} = \frac{\exp\!\left(x_{im}^{T} F_{m,k}\right)}
% {\sum_{j=1}^{K} \exp\!\left(x_{im}^{T} F_{m,j}\right)}
% \end{equation}


% \begin{itemize}
%     \item \textbf{Đầu vào:} $x_{im}$ vectơ đặc trưng con thứ $m$ của ảnh $i$.
%     \item \textbf{Tham số học được:} $F_{m,k}$ ma trận tham số của tầng tuyến tính.
%     \item \textbf{Đầu ra:} $p_{im,k}$ xác suất vectơ thuộc về từ mã thứ $k$.
% \end{itemize}

% Nhờ lớp trung gian $F_{m,k}$, quá trình mã hoá không còn dựa duy nhất vào khoảng cách hình học như trong phân cụm truyền thống, mà trở thành \textbf{một phép học xác suất mềm} giữa đặc trưng và các từ mã, xác xuất $p_{im,k}$ được điều chỉnh để tối ưu mục tiêu của toàn bộ mô hình. Thay vì gán vào một từ mã cứng nhắc, mô hình học ma trận tham số $F_{m,k}$ qua quá trình huấn luyện mạng nơ-ron. Cơ chế này cho phép mô hình linh hoạt hơn, tận dụng thông tin từ nhiều từ mã và được tối ưu cùng với toàn bộ mạng.

% Thứ hai, OPQN sử dụng các từ mã trực chuẩn (chi tiết ở mục 3.1.4), làm giảm tương quan ngầm giữa các đặc trưng và bộ mã, giúp phân phối xác suất có ý nghĩa rõ ràng.

% \subsubsection{Xây dựng lượng tử hoá mềm}
% Sau khi xác định vectơ xác suất $p_{im,k}$ qua hàm softmax, lượng tử hoá mềm $s_{im}$ được xây dựng bằng cách kết hợp tuyến tính các từ mã $C_{mk}$ với các giá trị xác suất tương ứng. Công thức được biểu diễn như sau:

% \begin{equation}
% s_{im} = \sum_{k=1}^K p_{im,k} . C_{mk}
% \end{equation}

% Trong đó, $C_{mk}$ là từ mã thứ $k$ trong bộ mã $C_m$ của không gian con thứ m, và $p_{im,k}$ là xác xuất gán được tính từ $x_{im}$ và tham số $F_{mk}$. Kết quả $s_{im}$ là một tổ hợp lồi của các từ mã, với tổng các xác suất $p_{im,k}$ bằng một, và giá trị không âm. Điều này cho phép $s_{im}$ tái hiện vectơ con $x_{im}$ một cách mềm mại, giảm thiểu lỗi lượng tử hoá so với việc gán cứng vào một từ mã duy nhất.

% Một đặc điểm quan trọng trong OPQN là việc tách biệt quá trình gán xác suất $p_{im,k}$ với các từ mã $C_{mk}$, giúp giảm sự phụ thuộc vào dữ liệu huấn luyện. Sự độc lập này cho phép $p_{im,k}$ được học một cách linh hoạt, trong khi các từ mã giữ vai trò cố định, góp phần tăng khả năng tổng quát hoá trên các tập dữ liệu mới, đặc biệt với các biến thể khuôn mặt chưa thấy. Ngoài ra, cách tiếp cận này tránh được những  những hạn chế của PQ, như hiện tượng bộ mã bị ảnh hưởng bởi độ chệch dữ liệu, đảm bảo độ ổn định và hiệu quả trong tìm kiếm quy mô lớn. Nhờ vậy, $ s_{im} $ không chỉ cải thiện độ chính xác mà còn hỗ trợ tính toán khoảng cách bất đối xứng trong giai đoạn tìm kiếm sau này.

% \subsubsection{Xây dựng lượng tử hoá cứng}
% Sau khi xây lượng tử hoá mềm $s_{im}$, OPQn chuyển sang phương pháp lượng tử hoá cứng trong giai đoạn kiểm tra để tối ưu hoá hiệu suất tìm kiếm. Quá trình này được thực hiện bằng cách xác định chỉ số $k^*$ của từ mã có xác suất cao nhất trong vectơ xác suất $p_{im}$. Công thức được biểu diễn như sau:

% \begin{equation}
% k^* = \arg _{k = 1,2,...,K}\max p_{im,k}
% \end{equation}

% Trong đó, giá trị $k^*$ là chỉ số của từ mã trong bộ mã $C_m$, mà có khả năng tái hiện tốt nhất vector $x_{im}$, tức là giá trị có xác suất gán lớn nhất trên phân phối xác suất $p_{im}$. Từ $k*$, lượng tử hoá cứng $h_{im}$ được định nghĩa đơn giản là:

% \begin{equation}
% h_{im} = C_{mk^*}
% \end{equation}

% Ở đây, $C_{mk^*}$ là từ mã tương ứng với từ mã thứ $k*$ trong bộ mã $C_m$. Phương pháp này chuyển đổi biểu diễn mềm $x_{im}$ thành một vector rời rạc $h_{im}$, phù hợp cho việc tính toán nhanh khoảng cách trong hệ thống truy xuất thông tin với quy mô lớn. Khác với giai đoạn huấn luyện, nơi lượng tử hoá mềm được ưu tiên để tối ưu hoá độ dốc, lượng tử hoá cứng chỉ được áp dụng trong giai đoạn truy xuất, để giảm độ phức tạp tính toán và bộ nhớ, đặc biệt khi sửa dụng bảng tra cứu để so sánh khoảng cách bất đối xứng. 

% Việc sử dụng $k^*$ đảm bảo rằng mỗi vector con $x_{im}$ được ánh xạ chính xác vào một từ mã đại diện, giúp duy trì tính phân biệt của đặc trưng trong khi tối ưu hoá hiệu suất. Điều này quan trọng trong ứng dụng truy xuất khuôn mặt, nơi độ chính xác của phép gán từ mã ảnh hưởng trực tiếp đến kết quả hàng xóm gần nhất. Phương pháp này tận dụng lợi thế của quá trình học trước đó ($p_{im,k}$ và $s_{im}$) để đạt được sự cân bằng giữa độ chính xác và tốc độ, đặt nền móng cho các bước tìm kiếm hiệu quả trong OPQN.

% \subsection{Sinh từ mã trực chuẩn}
% \subsubsection{Vấn đề của bộ mã trong phương pháp lượng tử hoá truyền thống và hướng khắc phục} 
% Trong các phương pháp lượng tử hoá tích truyền thống, bộ mã thường được học trực tiếp từ dữ liệu thông qua thuật toán như phân cụm K-Means. Cách tiếp cận này dẫn đến sự phụ thuộc mạnh mẽ của bộ mã vào phân bố của tập dữ liệu, có thể gây ra hiện tượng dư thừa thông tin giữa các từ mã hoặc lệch lạc từ mã khi dữ liệu không đại diện đầy đủ cho không gian đặc trưng. Giả định có một tập huấn luyện với độ chệch về một số loại hình ảnh, như tư thế hoặc ánh sáng nhất định, khả năng tổng quá hoá sẽ giảm khi áp dụng mô hình này trên dữ liệu mới hoặc danh tính chưa thấy, do bộ mã có thể bị học lệch.

% Để khắc phục những hạn chế này, OPQN sử dụng các từ mã cố định và trực chuẩn, không phụ thuộc vào dữ liệu huấn luyện vì đã được thiết kế trước. Cách tiếp cận này đảm bảo tính ổn định và tính toán hiệu quả, đồng thời tăng cường chất lượng lượng tử hoá bằng cách tận dụng các đặc tính toán học cố định. 

% Bằng cách này, OPQN chuyển thách thức từ việc học các từ mã sang việc học gán xác suất (như đã trình bày ở phần 3.1.3), giúp mô hình tăng khả năng khái quát hoá và giảm rủi ro với dữ liệu có tính biến thiên cao.

% % Tính chất của từ mã trực chuẩn
% Các từ mã trực chuẩn trong OPQN là các vector trong bộ mã $C_m$ thoả mãn hai điều kiện chính: Trực giao lẫn nhau và chuẩn hoá về độ dài bằng một. Cụ thể, đối với bất kỳ hai từ mã $C_{mk}$ và $C_{mj}$ ($k \neq j$ trong cùng một bộ mã $C_m \in \mathbb{R}^{d \times K}$, ta có:

% $C^T_{mk} C_{mj} = 0$ (trực giao), $\|C_{mk}\| = 1$ (chuẩn hoá)

% Hai đặc tính của từ mã trực chuẩn mạng lại các lợi ích quan trọng như sau:

% Thứ nhất, các từ mã không dư thừa và phân bố đồng đều trong không gian $\mathbb{R}^d$, phép trực giao đảm bảo tính không chồng chéo thông tin, tránh các dư thừa thường gặp đối với các bộ mã học từ dữ liệu. Thêm vào đó, đặc tính này giúp bao phủ toàn bộ không gian vector con một cách hiệu quả, tăng khả năng biểu diễn đa dạng các đặc trưng khuôn mặt và những biến thể nội lớp.

% Thứ hai, mỗi từ mã mang một hướng khác biệt rõ ràng, với góc giữa các từ mã là $\pi/2$, mỗi vector đại diện cho một hướng độc lập. Khi kết hợp với xác suất gán, mỗi từ mã đóng góp một thành phần thông tin riêng biệt, điều này làm cho việc lượng tử hoá trở nên chính xác hơn, giảm sai số khôi phục.

% Thứ ba, đặc tính trực chuẩn hỗ trợ tốt hơn cho việc ánh xạ xác suất $p_{im,k}$ và $s_{im}$ (từ phần 3.1.3). Tính chất toán học cố định của bộ mã giúp tối ưu hoá độ dốc trong quá trình huấn luyện.

% Tổng hợp lại, các đặc tính của bộ mã nâng cao tính thông tin và độ tin cậy của từ mã, góp phần vào hiệu suất tổng thể của OPQN trong nhiệm vụ truy xuất hình ảnh mặt người.

% \subsubsection{Cách sinh từ mã trực chuẩn} 
% Trong OPQn, các từ mã trực chuẩn được sinh ra dựa trên phép biến đổi cosin rời rạc loại II (DCT-II). Phép biến đổi này vốn tạo ra mộ tập vector cơ sở trực chuẩn trong $\mathbb{R}^d$; sau khi được chuẩn hoá bổ sung, các vector cơ sở vừa bảo toàn tính trực giao, vừa có độ dài chuẩn bằng một. Từ tập cơ sở này, $K$ vector đầu tiên được chọn để hình thành bộ mã khởi tạo $C_1$. Các bộ mã tiếp theo $C_m$ được xây dựng tuần tự thông qua phép nhân với ma trận cơ sở đã chuẩn hoá, nhờ đó vừa duy trì tính trực chuẩn, vừa gia tăng tính đa dạng giữa các bộ mã. Quá trình bắt đầu từ việc xây dựng ma trận cơ sở trực chuẩn $A \in \mathbb{R}^{d \times d}$, với các phần tử được tính theo công thức: 

% \begin{equation}
% A_{ij} = cos[j\pi \cdot \frac{i + \frac{1}{2}}{d}], i = 0, ..,d-1; j =  0,.., d-1
% \end{equation}


% Ma trận $A$ này được chuẩn hoá để đảm bảo tính trực chuẩn. Nhằm tạo đa dạng cho các bộ mã $C_m$ (với $m =  ,...M$, OPQN áp dụng một quy trình lặp: bắt đầu từ $C_1 = A[:,0 : K]$ (lấy $K$ cột đầu tiên của $A$), sau đó nhân lặp với ma trận cơ sở khác để sinh các bộ mã tiếp theo, đảm bảo tính đa dạng nhưng vẫn giữ đặc điểm trực chuẩn.

% \begin{algorithm}
% \caption{Sinh từ mã trực chuẩn được xác định }
% \begin{algorithmic}[1]
% \Require Kích thước đặc trưng $D$, số lượng bộ mã $M$, số lượng từ mã mỗi bộ mã $K$, kích thước vector con $d$ ($d = D/M$ và $d \geq K$)
% \Ensure Các bộ mã $C \in \mathbb{R}^{M \times d \times K}$

% \State Tính ma trận cơ sở cosine $A$ theo phương trình (5)
% \State $A[1,0] \leftarrow A[1,0]/\sqrt{2}$
% \State $A^\dagger \leftarrow \sqrt{2}A / \sqrt{d}$
% \State $C_1 = A^\dagger[:, :K]$
% \For{$m = 2$ to $M + 1$}
%     \State $C_m = A^ \dagger  * C_{m-1}$
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% Quy trình này được tóm tắt chi tiết trong thuật toán Algorithm 1. Cụ thể, với mỗi không gian con có kích thước $d = \frac{D}{M}$, ta khởi tạo một ma trận cơ sở cosin (theo công thức 3.5). Ma trận này sau đó được chuẩn hoá để thu được một cơ sở trực chuẩn $A^\dagger$, trong đó các cột đóng vai trò như những vector cơ sở trực giao.

% Từ cơ sở này, từ mã đầu tiên $C_1$ được hình thành bằng cách chọn $K$ vector cơ sở đầu tiên trong $A^\dagger$. Các bộ mã tiếp theo được tạo ra bằng cách nhân lặp lại với $A^\dagger$, tức là:
% $C_m = A^\dagger C_{m-1}$, $m = 2,.., M$

% Như vậy, sau quá trình này, ta thu được $M$ bộ mã, mỗi bộ mã gồm $K$ từ mã trực giao trong không gian con $d-$chiều. Thuật toán này đảm bảo tính nhất quán, tái lập và không phụ thuộc vào dữ liệu huấn luyện, với ràng buộc $ K \leq d $ để tránh vượt quá chiều không gian. Cách tiếp cận này giúp OPQN duy trì hiệu suất ổn định trong các ứng dụng thực tế.

% % Liên hệ với mục tiêu của OPQN
% Việc sử dụng từ mã trực chuẩn cố định trong OPQN tạo nên sự tách biệt rõ ràng với quá trình gán xác suất (có thể học được), góp phần vào mục tiêu chính của bài báo là tăng cường khả năng tổng quát hoá và giảm lỗi lượng tử hoá. 

% Tổng thể, cách sinh từ mã trực chuẩn hỗ trợ OPQN đạt hiệu suất vượt trội trong truy xuất hình ảnh mặt người với tập dữ liệu có khả năng mở rộng và là nền tảng cho các bước tối ưu hoá tiếp theo

% \subsection{Hàm mất mát phân loại kết hợp theo từng không gian con}
% \subsubsection{Mục tiêu}
% % Mục tiêu và trực giác(cách nhìn đơn giản) 
% Trong bối cảnh của mô hình OPQN, sau khi đã xây dựng lượng tử hoá mềm $s_{im}$ dựa trên khử tương quan đặc trưng - xác suất (Phần 3.1.3) và sinh từ mã trực chuẩn cố định (Phần 3.1.4), chúng ta cần một hàm mất mát hiệu quả để duy trì và nâng cao tính phân biệt của các đặc trưng tại từng không gian con. Mục tiêu cốt lõi của hàm mất mát này là giảm biến thiên nội lớp - nghĩa là làm cho các đặc trưng thuộc cùng một danh tính tụ lại gần nhau hơn - đồng thời tăng cường khoảng cách ngoại lớp - đẩy các đặc trưng thuộc các danh tính khác nhau ra xa hơn. Phân tích sâu hơn, việc áp dụng hàm mất mát này tại từng không gian con riêng lẽ thay vì toàn bộ đặc trưng toàn cục giúp khai thác tối đa cấu trúc dữ liệu phân mảnh, đặc biệt trong ngữ cảnh lượng tử hoá sản phẩm, nơi mỗi không gian con $m$ xử lý một phần độc lập của đặc trưng nút cổ chai $x_i$.

% Có thể hiểu rằng, trong nhiệm vụ truy xuất ảnh mặt người quy mô lớn, đặc trưng cần phải giữ được tính phân biệt mạnh mẽ ngay cả sau khi bị lượng tử hoá, vì lỗi lượng tử hoá có thể làm mờ ranh giới giữa các lớp. Bằng cách buộc cả đặc trưng gốc $x_{im}$ và lượng tử hoá mềm $s_{im}$ phải tuân theo cùng một tiêu chí phân lớp, hàm mất mát này khuyến khích sự tương thích giữa hai biểu diễn trên, giúp giảm lỗi tái tạo và tăng khả năng tổng quát hoá trên các danh tính chưa thấy. Điều này đặc biệt quan trọng trong OPQN, nơi mục tiêu là cân bằng giữa tính chính xác và hiệu quả lưu trữ, tìm kiếm, vì hàm mất mát này giúp tối ưu hoá đồng thời mạng xương sống và quá trình lượng tử hoá mà không làm suy giảm hiệu suất nhận dạng.

% \subsubsection{Chuẩn hoá}
% Trước khi tính hàm mất mát, chúng ta cần chuẩn hoá $\ell_2$ cho tất cả các vector liên quan, nhằm loại bỏ biến thiên về độ dài và tập trung vào thông tin góc độ, vốn phù hợp cho các nhiệm vụ nhận dạng khuôn mặt. 

% Cụ thể, $ x_{im} \leftarrow x_{im} / \|x_{im}\|_2 $, $s_{im} \leftarrow s_{im} / \|s_{im}\|_2$, và trọng số phân lớp $W_{m,c} \leftarrow W_{m,c} / \|W_{m,c}\|_2$ với ($W_m \in \mathbb{R}^{d \times C}$ là ma trận trọng số cho bộ phân lớp tới không gian con $m$, mỗi $W_{m,c}$ đại diện cho hướng lý tưởng của đặc trưng thuộc lớp $c$ (danh tính thứ $c \in C$) trong không gian vectơ con $\mathbb{R}^d$. 

% Phân tích kỹ hơn, chuẩn hoá này chuyển đổi không gian Ơ-clid thành không gian cầu, nơi độ tương tự đo bằng độ tương đồng co-sine qua tích vô hướng: $\cos \theta = v^T_1 v_2$. Việc chuẩn hoá đồng bộ cả $x_{im}, s_{im}, W_{m,c}$ đảm bảo rằng các phép tính cosine trong hàm mất mát đều được thực hiện trên cùng một thang đo, tăng tính ổn định và hội tụ trong huấn luyện. Đồng thời việc chuẩn hoá liên tục giúp tránh hiện tượng bùng nổ đạo hàm trong không gian cao chiều.

% \subsubsection{Hàm mất mát cho các đặc trưng gốc $L_x$}
% Để khuyến khích tính phân biệt và cô đọng cho đặc trưng gốc $x_{im}$, OPQN áp dụng hàm mất mát trung bình mũ biên độ góc, một biến thể phổ biến trong các mô hình nhận dạng khuôn mặt để cải thiện sự tách biệt lớp. Công thức cho $L_x$ được biểu diễn như sau:

% \begin{equation}
%     L_x = \sum_{i=1}^N \sum_{m=1}^M - \log \frac{e^{r(\cos\theta_{y_i, x_{im}} - u)}}{e^{r(\cos\theta_{y_i, x_{im}} - u)} + \sum_{j \neq y_i} e^{r\cos\theta_{j, x_{im}}}}
% \end{equation}

% Trong đó, $\cos \theta_{y_i, x_{im}} = x^T_{im} W_{m,y_i}$ sau chuẩn hoá, với $W_{m,y_i} \in \mathbb{R}^d$ là vector trọng số tương ứng với lớp $y_i$ trong ma trận trọng số phân lớp $W_m \in \mathbb{R}^{d \times C}$ cho không gian con $m$. Giá trị $\cos \theta_{y_i, x_{im}}$ đại diện cho độ tương tự cosine giữa vectơ con $x_{im}$ và vectơ trọng số của lớp đúng $y_i$, phản ảnh mức độ gần gũi góc độ giữa đặc trưng và trọng số sau khi cả hai được chuẩn hoá $\ell_2$. Ma trận $W_m$ chứa $C$ vector trọng số $W_{m,c}$, $ c \in {1,..,C}$, với $W_{m,y_i}$ là cột tương ứng với nhãn $y_i$ của mẫu $i$.

% Trong công thức, $r > 0$ là hệ số để khuyếch đại đạo hàm và ổn định phân phối hàm trung bình mũ, trong khi $u > 0$ là biên độ co-sine, một hằng số được thêm vào để phạt các trường hợp co-sine gần 1 nhưng không đủ cô đặc, tức là khi các mẫu thuộc về lớp đó nhưng khoảng cách giữa mẫu và trọng tâm lớp đó vẫn chưa đủ nhỏ theo yêu cầu của biên độ u. Trong triển khai thực tế, các siêu tham số $u$ thường từ khoảng 0.1-0.5, và hệ số khuyếch đại $r$ thường từ khoảng 30-64, được chọn dựa trên kinh nghiệm từ các mô hình nhận dạng khuôn mặt.

% Tổng kép $ \sum_{i=1}^N \sum_{m=1}^M $ chạy qua tất cả $N$ mẫu và $M$ không gian con, đảm bảo hàm mất mát được tính theo từng không gian con, mỗi không gian con $x_m$ tập trung học một khía cạnh phân biệt khác nhau của khuôn mặt, giúp chuyên môn hoá đặc trưng. Nếu một không gian con bị nhiễu, ví dụ như do che khuất một phần khuôn mặt, các không gian con còn lại vẫn có thể cung cấp thông tin phân biệt chính xác. Điều này làm tăng độ bền vững của mô hình trước yếu tố gây nhiễu trong thế giới thực

% Hàm log-softmax với biên độ $u$ làm tăng độ khó trong việc đạt xác suất cao cho lớp đúng, buộc mô hình phải học từ các đặc trưng phân biệt mạnh mẽ hơn, tăng độ cô đọng và tách biệt, vì chúng ép các điểm dữ liệu cùng lớp tụ lại trong một góc nhỏ và tách biệt các lớp khác.
 
% \subsubsection{Hàm mất mát cho các đặc trưng đã được lượng tử hoá $L_s$}
% Tương tự với $L_x$, hàm mất mát trung bình mũ biên độ góc được áp dụng lên đặc trưng lượng tử hoá mềm $s_{im}$ (đã được chuẩn hoá $\ell_2$) để đảm bảo chúng duy trì cả tính phân biệt và tính cô đọng tương được đặc trưng gốc $x_{im}$. Mục tiêu không chỉ giữ cho $s_{im}$ phản ảnh chính xác các đặc trưng nhận dạng của $x_{im}$, mà còn ép các điểm dữ liệu thuộc cùng một lớp tụ lại gần trọng tâm lớp trong không gian góc độ, từ đó giảm khoảng cách giữa hai biểu diễn và cải thiện hiệu quả lượng tử hoá. Công thức cho $L_s$ được biểu diễn như sau:

% \begin{equation}
%     L_s = \sum_{i=1}^N \sum_{m=1}^M - \log \frac{e^{r(\cos\theta_{y_i, s_{im}} - u)}}{e^{r(\cos\theta_{y_i, s_{im}} - u)} + \sum_{j \neq y_i} e^{r\cos\theta_{j, s_{im}}}}
% \end{equation}

% Trong đó, $\cos \theta_{y_i, s_{im}} = s^T_{im} W_{m,y_i}$, với $W_{m,y_i} \in \mathbb{R}^d$ là vector trọng số tương ứng với lớp $y_i$ trong ma trận trọng số phân lớp $W_m \in \mathbb{R}^{d \times C}$ cho không gian con $m$. Sau chuẩn hoá, giá trị $\cos \theta_{y_i, s_{im}}$ thể hiện mức độ tương tự co-sine giữa $s_{im}$ và trọng số lớp đúng, phản ánh  mức độ gần gũi góc độ giữa đặc trưng lượng tử hoá mềm và lý tưởng hoá lớp. Các tham số $r$ và $u$ được giữ nguyên như trong $L_x$ để đảm bảo sự tương thích giữa $x_{im}$ và $s_{im}$ giúp giảm thiểu sai lệch do quá trình lượng tử hoá.

% Phân tích sâu hơn, $L_s$ đóng vai trò quan trọng trong việc khắc phục nhược điểm tiềm ẩn của lượng tử hoá, nơi thông tin phân biệt có thể bị mất do việc nén đặc trưng. Không giống như $L_x$ tập trung vào đặc trưng gốc, $L_s$ đặc biệt chú trọng đến việc điều chỉnh $s_{im}$ sao cho nó không chỉ tách biệt các lớp mà còn duy trì sự cô đọng nội lớp, ngay cả khi $s_{im}$ là tổ hợp lồi của các từ mã trực chuẩn. Biên độ $u$ trong $L_s$ buộc mô hình phải học cách tối ưu hoá xác suất $p_{im,k}$ (được tính từ hàm trung bình mũ của $x_{im}$ và $F_{mk}$) sao cho $s_{im}$ gần với trọng tâm lớp hơn, giảm biến thể nội lớp trong không gian lượng tử hoá. Điều này đặc biệt quan trọng trong OPQN, vì lượng tử hoá mềm cần giữ được tính chất nhận dạng của đặc trưng gốc để hỗ trợ hiệu quả trong việc tìm kiếm hàng xóm gần nhất, nơi sự cô đọng  và tách biệt là yếu tố quyết định.

% Lý do sử dụng $L_s$ nằm ở việc nó mở rộng tính năng của hàm trung bình mũ biên độ góc từ đặc trưng gốc sang đặc trưng lượng tử hoá, đảm bảo quá trình nén không làm suy giảm khả năng phân lớp. Trong ngữ cảnh OPQN, việc duy trì cả tính phân biệt và cô đọng cho $s_{im}$ giúp giảm sai số lượng tử hoá, đặc biệt khi dữ liệu khuôn mặt có biến thiên lớn. So với $L_x$, $L_s$ không chỉ củng cố tính chất nhận dạng mà còn hỗ trợ tối ưu hoá ma trận biến đổi $F$ (được sử dụng để tính $p_{im,k}$, tạo sự liên kết chặt chẽ giữa quá trình lượng tử hoá và phân lớp. Điều này đặt nền móng cho việc chuyển sang lượng tử hoá cứng trong giai đoạn kiểm tra, đồng thời chuẩn bị cho các bước tiếp theo như tối thiểu hoá độ cô đặc.

% \subsubsection{Hàm mất mát liên hợp}
% Dựa trên các hàm mất mát riêng lẽ đã được xây dựng, OPQN tích hợp chúng thành một hàm mất mát liên hợp để tối ưu hoá toàn diện mô hình. Hàm mất mát phân lớp liên hợp theo không gian con, được ký hiệu là $L_{clf}$, được xây dựng bằng cách tích hợp mất mát cho đặc trưng gốc $L_x$ và mất mát cho đặc trưng lượng tử hoá mềm $L_s$ theo công thức:

% \begin{equation}
% L_{clf} = \frac{1}{2MN} (L_x + L_s)
% \end{equation}

% Với $M$ là số không gian con, $N$ là số mẫu huấn luyện, hệ số chuẩn hoá $\frac{1}{2MN}$ đóng vai trò quan trọng trong việc bình quân hoá mất mát trên toàn bộ $M$ không gian con và $N$ mẫu, ngăn chặn hiện tượng thiên lệch do chênh lệch kích thước dữ liệu hoặc số lượng không gian con. Yếu tố $\frac{1}{2}$ đảm bảo sự cân bằng giữa đóng góp của $L_x$ và $L_s$, thúc đẩy sự hài hoá trong quá trình tối ưu hoá đặc trưng gốc và đặc trưng lượng tử hoá, tránh việc ưu tiên quá mực một trong hai phần. Mục tiêu của hàm mất mát nhằm tối thiểu hoá đồng thời các tham số mạng xương sống $ \Theta $, ma trận biến đổi $F$ và ma trận trọng số phân lớp $W$

 
% %Xuất phát với nhu cầu tạo ra một cơ chế liên hợp nhằm bảo toàn độ tương tự trong suốt quá trình xử lý OPQN, thay vì chỉ dựa vào một loại mất mát đơn lẻ, cách tiếp cận này tận dụng sức mạnh kết hợp của $L_x$ và $L_s$ để đảm bảo rằng quá trình lượng tử hoá không làm suy giảm hiệu suất phân lớp tổng thể. $L_{clf}$, trong bài toán OPQN, đóng vai trò trung tâm trong việc kết nối các giai đoạn khác nhau của mô hình, từ trích xuất đặc trưng đến lượng tử hoá và phân lớp, tối ưu hoá toàn bộ quy trình đầu cuối. 

% % Giải thích trực quan và vai trò trong quy trình xử lý
% Về mặt trực quan, $L_{clf}$ có thể được hình dung như một quá trình chiếu các đặc trưng lên không gian cầu đơn vị, nơi biên độ $u$ hoạt động như một lực kéo các điểm thuộc cùng các lớp lại gần nhau, đồng thời đẩy các điểm thuộc các lớp khác ra xa, tạo ra một cấu trúc không gian rõ ràng và phân tách tốt. Sự kết hợp của $L_x$ và $L_s$ trong $L_{clf}$ đảm bảo rằng đặc trưng lượng tử hoá mềm $s_{im}$ không chỉ theo sát đặc trưng gốc $x_{im}$ về mặt nhận dạng, mà còn hỗ trợ tối ưu hoá toàn diện, giảm thiểu tác động tiêu cực từ quá trình nén dữ liệu. 

% Việc chỉ sử dụng $L_x$ có thể bỏ qua việc điều chỉnh $s_{im}$, trong khi chỉ dựa vào $L_s$ có thể làm suy yếu khả năng học của mạng xương sống. Hàm mất mát liên hợp giải quyết vấn đề này bằng phân bổ đạo hàm một cách cân bằng qua quá trình lan truyền ngược, giúp điều chỉnh đồng thời $ \Theta $, $F$ và $W$, từ đó giảm thiểu sai số lượng tử hoá một cách hiệu quả.

% Trong quá trình xử lý OPQN, $L_{clf}$ đóng vai trò quan trọng như một cầu nỗi giữa các giai đoạn. Chúng chuẩn bị các vector nhúng (vector đặc trưng được mô hình học có chất lượng cao), để cho phép tối thiểu hoá (Phần 3.1.6) dễ dàng ép phân phối xác suất $p_{mk}$ về one-hot, rút ngắn khoảng cách giữa lượng tử hoá mềm và cứng. Đồng thời, chúng đặt nền móng cho truy xuất khoảng cách bất đối xứng (phần 3.1.8) bằng cách đảm bảo rằng các đặc trưng lượng tử hoá cứng $h_{im}$ (sau khi chuyển từ $s_{im}$) vẫn giữ được tính phân biệt cần thiết, tối ưu hoá cả tốc độ và độ chính xác trong quá trình tìm kiếm quy mô lớn. Như vậy, $L_{clf}$ không chỉ là một công cụ tối ưu hoá mà còn là yếu tố then chốt trong việc duy trì hiệu quả tổng thể của mô hình trên các kịch bản thực tế đa dạng.

% \subsection{Tối thiểu hoá độ cô đặc(entropy) cho việc gán mã one-hot}
% Trong mô hình OPQN, mặc dù hàm mất mát phân lớp liên hợp $L_{clf}$ phần (3.1.5) đã đảm bảo tính phân biệt cho cả đặc trưng gốc $x_{im}$ và lượng tử hoá mềm $s_{im}$ , vẫn tồn tại khoảng cách đáng kể giữa $s_{im}$ - biểu diễn như một tổ hợp lồi của các từ mã theo phân phối xác suất $p_{im}$ - và lượng tử hoá cứng $h_{im}$ - dạng one-hot chỉ gán vào một từ mã duy nhất. Vấn đề phát sinh từ việc huấn luyện chỉ đựa vào $L_{clf}$, vốn không trực tiếp khuyến khích $p_{im}$ hội tụ về phân phối one-hot, dẫn đến sai lệch giữa $s_{im}$ và $h_{im}$ trong giai đoạn truy xuất. Sai lệch này có thể làm tăng lỗi lượng tử hoá, đặc biệt trong cách kịch bản tìm kiếm khuôn mặt quy mô lớn, nơi $h_{im}$ được sử dụng để nén dữ liệu và tính khoảng cách hiệu quả.

% Mục tiêu của phần tối thiểu hoá độ bất định, độ hỗn loạn là giới thiệu một bộ chuẩn hoá dựa trên độ bất định để giảm thiểu khoảng cách này, bằng cách ép phân phối $p_{im}$ tiếng gần hơn đến dạng one-hot. Việc này không chỉ cải thiện sự tương thích giữa lượng tử hoá mềm và lượng tử hoá cứng, mà còn giảm lỗi tái hiện tổng thể, tăng cường khả năng tổng quá hoá của mô hình trên dữ liệu chưa thấy. Theo phân tích trong OPQN(Phần 3.4), phép chuẩn hoá độ bất định đóng vai trò quan trọng trong việc cân bằng giữa tính linh hoạt của lượng tử hoá mềm trong huấn luyện và tính hiệu quả của lượng tử hoá cứng trong suy diễn.

% \subsubsection{ Định nghĩa hàm mất mát độ bất định}
% Hàm mất mát độ bất định được sử dụng như một phương pháp chuẩn hoá để đo lường độ không chắc chắn trong phân phối $p_{im}$ và thúc đẩy sự hội tụ về one-hot. Công thức hàm mất mát độ bất định $L_{ent}$ được định nghĩa như sau:
% \begin{equation}
%     L_{ent} =  -\frac{1}{MN} \sum_{i=1}^N \sum_{m=1}^M \sum_{k=1}^K p_{im,k} \log p_{im,k}
% \end{equation}

% Độ bất định của một phân phối đạt giá trị tối thiểu bằng 0 khi và chỉ khi phân phối đó là one-hot, tương ứng với gán rõ ràng vào một từ mã. Trong công thức, tổng nội $\sum_{k=1}^K p_{im,k} \log p_{im,k}$ tính độ bất định cho mỗi $p_{im}$ tại không gian con $m$ và mẫu $i$, với dấu âm để chuyển thành hàm mất mát tối thiểu hoá. Hệ số chuẩn hoá $ -\frac{1}{MN}$ bình quân hoá trên tất cả không gian con và mẫu, đảm bảo hàm mất mát không bị thiên lệch bởi kích thước dữ liệu. Việc tối thiểu hoá $L_{ent}$ thúc đẩy $p_{im}$ trở nên sắc nét hơn, giảm độ phân tán và tăng cường tính quyết đoán trong gán, từ đó giảm sai số lượng tử hoá mà không ảnh hưởng đến đạo hàm từ phân lớp.

% \subsubsection{ Tích hợp với hàm mất mát phân lớp}
% Để cân bằng giữa mục tiêu phân lớp và phương pháp chuẩn hoá độ bất định, OPQN tích hợp hàm mất mát bất định vào hàm mất mát tổng thể như sau:

% \begin{equation}
%     L = L_{clf} + \lambda L_{ent}
% \end{equation}

% Với $\lambda$ là trọng số siêu tham số kiểm soát cường độ của hàm chuẩn hoá độ bất định. $L_{clf}$ ưu tiên tính phân biệt, trong khi $L_{ent}$ tập trung vào sự sắt nét của $p_{im}$; $\lambda$ đóng vai trò điều tiết, tránh hiện tượng quá chuẩn hoá (khi $\lambda$ lớn, có thể làm mất đạo hàm mềm từ $L_{clf}$), hoặc thiếu chuẩn hoá (khi $\lambda$ nhỏ, không đủ ép one-hot). Theo bài báo, $\lambda = 0.1$ được chọn qua kiểm định chéo để đạt cân bằng tối ưu, đảm bảo hàm mất mát tổng hợp không chỉ giảm lỗi phân lớp mà còn cải thiện sự tương thích giữa lượng tử hoá cứng và lượng tử hoá mềm. Việc tích hợp này tạo ra một khung hàm mất mát lai, nơi hàm chuẩn hoá độ bất định bổ trợ cho $L_{clf}$ bằng cách tăng cường tính ổn định trong huấn luyện, đặc biệt với mã ngắn nơi sai số lượng tử hoá dễ tăng.

% \subsubsection{ Các đạo hàm quan trọng để minh hoạ cách lan truyền ngược hoạt động}
% Để minh hoạ cách hàm mất mát độ bất định lan truyền ảnh hưởng qua quá trình lan truyền ngược, cần xem xét các đạo hàm chính liên quan đến logit $g_{mk} = x^T_{im} F_{m,k}$, nơi $p_{im} =  softmax(g_m)$. Đạo hàm của $p_{im,k}$ theo $g_{m,k}$ được tính như sau:

% $\frac{\partial p_{im,k}}{\partial g_{m,k}} = p_{im,k} (1 - p_{im,k})$, $\frac{\partial p_{im,k}}{\partial g_{m,j}} (j \neq k) =  p_{im,k}p_{im,j}$

% Tiếp theo, đạo hàm của $s_{im}$ theo $g_{m,k}$:

% $\frac{\partial s_{im}}{\partial g_{m,k}} = p_{im,k}(C_{m,k} - s_{im})$

% Cuối cùng, đạo hàm của $L_{ent}$ theo $g_{m,k}$:

% $\frac{\partial L_{ent}}{\partial g_{m,k}} = p_{im,k} (\sum_{j=1}^K p_{im,j} \log p_{im,j} - \log p_{im,k})$

% Các đạo hàm này minh hoạ cách hàm mất mát bất định điều chỉnh đạo hàm để ép $p_{im}$ sắc nét hơn, ảnh hưởng đến việc cập nhật $F_m$ qua $g_{m,k}$. Trong quá trình lan truyền ngược, đạo hàm từ $L_{ent}$ kết hợp với đạo hàm từ $L_{clf}$ để cân bằng giữa phân lớp và chuẩn hoá, giảm khoảng cách lượng tử hoá mềm và lượng tử hoá cứng mà không làm gián đoạn quá trình học.

% Về mặt trực quan, hàm mất mát bất định hoạt động như một lực kéo phân phối $p_{im}$ từ trạng thái phân tán (độ bất định cao, các thành phần gần đều nhau) sang trạng thái có đỉnh duy nhất (độ bất định thấp, gần one-hot), khiến $s_{im}$ dịch chuyển dần về một từ mã cụ thể - gần với $h_{im}$. 

% \subsection{Quá trình học và tối ưu hoá}
% % Mục tiêu và trực giác
% Quy trình học và tối ưu hoá trong OPQN nhằm cập nhất các tham số mô hình một cách đầu cuối, đảm bảo hội tụ ổn định và nâng cao chất lượng đặc trưng lượng tử hoá mà không phụ thuộc vào việc học các từ mã. Mục tiêu chính là tối ưu hoá đồng thời tham số mạng xương sống $\Theta$, ma trận biến đổi tuyến tinh $F$ và trọng số phân lớp $W$ thông qua SGD và lan truyền ngược, tận dụng đạo hàm từ cả hàm mất mát phân lớp $L_{clf}$ (tăng tính phân biệt) và hàm mất mát entropy (ép gán one-hot), giảm lỗi tái hiện tổng thể. 

% %Trực giác đằng sau là lan truyền gradient tổng hợp từ $ L $ qua các lớp mạng, điều chỉnh logit, gán xác suất, và đặc trưng bottleneck để tối ưu hóa end-to-end. Không giống các phương pháp lượng tử hóa truyền thống phụ thuộc codewords học, OPQN sử dụng codewords cố định, nên tối ưu hóa tập trung vào học gán và phân lớp, giảm độ phức tạp và tăng tốc độ hội tụ, đồng thời nâng cao khả năng tổng quát hóa trên danh tính chưa thấy

% \subsubsection{Tham số học}
% Các tham số cần học trong OPQN bao gồm, $\Theta$ (Tập hợp tham số của mạng xương sống để trích xuất đặc trưng nút cổ chai $x_i$, $F = [F_1,...,F_M]$ (Ma trận biến đổi tuyến tính để tính logit và xác suất gán, với mỗi $F_m \in R^{d \times K}$, và $W = [W_1,..,W_M]$ (Ma trận trọng số phân lớp, với mỗi $W_m \in \mathbb{R}^{d \times C}$.

% $\Theta$ chịu trách nhiệm tạo đặc trưng cao cấp từ hình ảnh đầu vào, $F$ đóng vai trò cầu nối để biến đổi vector con thành logit cho gán các từ mã và $W$ đảm bảo phân lớp chính xác tại từng không gian con. Các tham số này được học đồng thời để đảm bảo tính nhất quán giữa trích xuất đặc trưng và phân lớp, với $F$ giúp tôi ưu hoá gán xác suất dựa trên đặc trưng từ $\Theta$, tăng cường hiệu quả trong không gian cao chiều. 

% \subsubsection{ Quy trình tối ưu hoá}
% Quy trình tối ưu hoá sử dụng phép giảm đạo hàm ngẫu nhiên theo lô nhỏ (Mini Batch SGD) để tối thiểu hoá hàm mất mát tổng thể $ L = L_{clf} + \lambda L_{ent} $, với lan truyền ngược là quá trình lan truyền đạo hàm qua các lớp mạng. Trong mỗi lần lặp, mẫu lô nhỏ được lấy ngẫu nhiên từ tập huấn luyện, lan truyền dọc để tính đặc trưng thắt nút cổ chai $x_i = f(\Theta, I_i)$, chia thành các vector con $x_{im}$, tính logit $g_m$, xác suất $p_im$, lượng tử hoá mềm $s_{im}$, và cuối cùng là hàm mất mát phân lớp cho cả $x_{im}$ và $s_{im}$; sau đó lan truyền ngược đạo hàm để cập nhật $W$, $F$ và $\Theta$.

% Phân tích kỹ, việc truyền thẳng bắt đầu từ mạng xương sống để tạo $x_i$, sau đó biến đổi tuyến tính qua $F$ để có logit, đảm bảo lượng tử hoá mềm phản ánh đặc trưng gốc. Lan truyền ngược, lan truyền đạo hàm tổng hợp từ L, với $L_{clf}$ điều chỉnh $W$ và $\Theta$ cho phân lớp, $L_{ent}$ (qua $\lambda$) hỗ trợ $F$ để tinh chỉnh gán xác suất. Lý do sử dụng phép giảm đạo hàm ngẫu nhiên theo lô nhỏ nằm ở hiệu quả với dữ liệu lớn, giảm nhiễu đạo hàm, tránh các điểm cực tiểu tương đối, tăng tốc độ hội tụ trong mô hình sâu.

% \subsubsection{Quá trình lan truyền ngược}
% Để minh hoạ quá trình lan truyền nguọc, cần tính đạo hàm của hàm mất mát tổng thể $L$ theo các tham số, bắt đầu từ logit $g_{mk}$, dựa trên đạo hàm của $L_{clf}$ (vì $L_{ent}$ đã được phân tích ở 3.1.6). 

% Đạo hàm của $L$ theo $F_{mk}$ (Eq:14 trong bài báo)

% $\frac{\partial L}{\partial F_{mk}} = \left[ \frac{1}{2} \left( \frac{\partial L_x}{\partial x_{im}} + \frac{\partial L_s}{\partial s_{im}} \frac{\partial s_{im}}{\partial g_{mk}} \right)^T \right] x_{im} + \lambda \frac{\partial L_{ent}}{\partial F_{mk}}$

% Đạo hàm của $L$ theo $W_{mk}$ (Eq. 15)

% $\frac{\partial L}{\partial W_{mk}} = \frac{1}{2} \left( \frac{\partial L_x}{\partial W_{mk}} + \frac{\partial L_s}{\partial W_{mk}} \right)$

% Đạo hàm của $L$ theo $x_{im}$ (Eq. 16)

% $$\frac{\partial L}{\partial x_{im}} = \frac{1}{2} \frac{\partial L_x}{\partial x_{im}} + \frac{1}{2} \left( \frac{\partial L_s}{\partial s_{im}} \frac{\partial s_{im}}{\partial g_{mk}} \right) F_{mk} + \lambda \frac{\partial L_{ent}}{\partial x_{im}}.$$

% Đạo hàm theo $F_{mk}$ và $x_{im}$ bao gồm cả đóng góp từ $L_{ent}$ (qua $\lambda$), điều chỉnh gán xác suất và đặc trưng để ép one-hot, trong khi đạo hàm theo $W_{mk}$ chủ yếu từ $L_{clf}$ để tối ưu hoá phân lớp. 

% \subsubsection{Quá trình huấn luyện OPQN}
% Thuật toán 2 tóm tắt quy trình huấn luyện OPQN như sau: 
% \begin{algorithm}
% \caption{Quy trình huấn luyện OPQN}
% \begin{algorithmic}[2]
% \Require Tập huấn luyện $\{I_i\}_{i=1}^N$ với nhãn $y$, mạng $f(\cdot)$, kích thước bộ từ mã $M \times d \times K$
% \Ensure Các tham số đã huấn luyện $\Theta, F, W$

% \State Sinh các từ mã trực chuẩn bằng Thuật toán 1
% \State Khởi tạo các tham số mạng nền $\Theta$, lớp biến đổi tuyến tính $F$, ma trận trọng số phân loại $W$
% \Repeat
%     \State Lấy ngẫu nhiên một mini-batch từ tập huấn luyện
%     \State Tính $x_i = f(\Theta; I_i)$ cho từng ảnh trong mini-batch
%     \State Tính hàm mục tiêu $L$ theo phương trình (10)
%     \State Tính đạo hàm của $L$ theo $W$, $F$, và $x_{im}$ theo các phương trình (15), (14) và (16)
%     \State Lan truyền ngược gradient và cập nhật các tham số $W$, $F$, $\Theta$
% \Until{hội tụ}
% \end{algorithmic}
% \end{algorithm}

% Các bước chi tiết như sau:
% Đầu tiên, mô hình sinh từ mã trực chuẩn bằng Algorithm 1, sử dụng Phép biến đổi cosine rời rạc để tạo từ mã cố định. Sau đó, vòng lặp sử dụng SGD để cập nhật tham số dần dần, với điều kiện dừng khi hàm mất mát ổn định hoặc đạt số lần lặp tối đa. Tiếp theo, lấy tập con nhỏ ngẫu nhiên từ tập huấn luyện để giảm chi phí tính toán, truyền thẳng tập con nhỏ ấy quá mô hình để tính $x_i = f(\Theta; I_i)$ cho mỗi hình ảnh. 
% Sau đó, tính hàm mất mát tổng thể $L$ từ hàm mất mát phân lớp và hàm mất mát entropy dựa trên $x_{im}, s_{im}, p_{im}$. Tiếp theo, đạo hàm $L$ được tính theo $ W $, $ F $, và $ x_{im} $. Các đạo hàm này được lan truyền ngược qua mạng, từ phân lớp và lượng tử hoá mềm về mạng xương sống để cập nhật các tham số bằng SGD và tốc độ học.

% \subsection{So sánh khoảng cách bất đối xứng trong truy xuất}
% Trong giai đoạn truy vấn của hệ thống truy xuất hình ảnh khuôn mặt quy mô lớn, việc lựa chọn phép đo lường tương đồng đóng vai trò quan trọng trong việc cân bằng giữa độ chính xác và hiệu suất tính toán. Theo các nghiên cứu gần đây, chúng tôi áp dụng khoảng cách lượng tử hoá bất đối xứng (AQD) làm phép đo lường chính, cho phép sử dụng lượng tử hoá mềm để biểu diễn truy vấn trong khi mã hoá cơ sở dữ liệu bằng lượng tử hoá cứng. Cách tiếp cận này không chỉ giảm đáng kể lượng tài nguyên của bộ nhớ, mà còn tăng tốc độ truy vấn, phù hợp với kiến trúc gọn nhẹ được đề xuất, nơi tài nguyên tính toán bị hạn chế ở quy mô lớn.

% Quy trình xử lý giữa các truy vấn và các mục trong cơ sở dữ liệu được thiết kế khác biệt để tận dụng ưu điểm của lượng tử hoá. Đối với một truy vấn $q$, chúng tôi lan truyền nó qua mô hình cho đến lớp biến đổi tuyến tính, sau đó áp dụng hàm trung bình mũ, để thu được vector xác suất $p_{qm}$ cho từng vector con $x_{qm}$. Kết hợp với bộ mã $C_m$, ta nhận được lượng tử hoá mềm $s_{qm}$. Ngược lại, đối với mỗi hình ảnh từ cơ sở dữ liệu $I_i$, chúng tôi tiền tính toán {$p_{im}$} theo quy trình tương tự truy vấn, và liên kết nó với lượng tử hoá cứng {$h_{im}$} thông qua chỉ số của giá trị lớn nhất trong {$p_{im}$}. Ma trận $B \in \mathbb{R}^{N \times M}$ được xây dựng trước, trong đó mỗi phần từ $b_{im}$ lưu chỉ số $k^*$ của từ mã theo công thức tính trong lượng tử hoá cứng, giúp mã hoá hiệu quả các đặc trưng gốc thành mã nhị phân.

% Khoảng cách AQD giữ truy vấn $q$ và $I_i$ được tính bằng tổng bình phương Ơ-clid giữa lượng tử hoá mềm của truy vấn và lượng tử hoá cứng của cơ sở dữ liệu, cụ thể. 

% \begin{equation}
%     AQD(q,I_i) = \sum_{m=1}^M \|s_{qm} - h_{im}\|_2^2 = \sum_{m=1}^M \|C_m p_{qm} - C_m b_{im}\|_2^2
% \end{equation}

% Công thức này đảm bảo việc so sánh tương đồng được thực hiện chính xác trong không gian lượng tử hoá, đồng thời giữ nguyên thông tin phân biệt giữa các đặc trưng khuôn mặt dưới các biến đổi nội lớp. Nhờ tính trực chuẩn của từ mã $C_m$ công thức trên có thể được đơn giản hoá đáng kể. Bằng cách mở rộng vế phải và loại bỏ các thành phần hằng số hoặc không phụ thuộc vào $C_m b_{im}$, ta thu được:

% \begin{equation}
%     \arg\min_i \text{AQD}(q, I_i) = \arg\min_i \sum_{m=1}^M -2 p_{qm}^T C_m^T C_m b_{im} = \arg\max_i \sum_{m=1}^M p_{qm, b_{im}}
% \end{equation}

% Kết quả này cho thấy việc tối ưu hoá AQD chỉ phụ thuộc vào $ \{p_{qm}\}_{m=1}^M $ và $ \{b_{im}\}_{m=1}^M $, cho phép thực hiện so sánh tương đồng lượng tử hoá một cách hiệu quả bằng cách sử dụng các bảng tra cứu. Cụ thể, chúng tôi xây dụng $M$ bảng tra cứu $\{LUT_m\}$ tương ứng với $M$ vector xác suất $\{p_q\}_{m=1}^M$ trong đó, $LUT_m[i] = b_{im}$. Vì ma trận $B$ được tiền tính toán, quy trình tìm kiếm chỉ yêu cầu một số phép cộng cơ bản, giảm thiểu độ phức tạp thời gian so với các phương pháp truyền thống.

% Để triển khai quy trình truy xuất top-$k$ hiệu quả, chúng tôi đề xuất thuật toán 3: 

% \begin{algorithm}
% \caption{Quy trình truy hồi Top-k OPQN}
% \label{alg:opqn}
% \begin{algorithmic}[3]
% \Require Tập ảnh cơ sở dữ liệu $DB = \{db_i\}_{i=1}^{|DB|}$, 
%         tập ảnh truy vấn $Q = \{q_j\}_{j=1}^{|Q|}$, 
%         mô hình đã huấn luyện;
% \Ensure Top $k$ ảnh trong $DB$ cho mỗi $q_i$;
% \State Truyền tiến $DB$ qua mô hình trước, và tính trước ma trận chỉ số $B$ theo (2) và (4);
% \State Xây dựng LUTs cho $DB$ dựa trên ma trận $B$;
% \For{$i = 1, 2, \dots, |Q|$}
%     \State Truyền tiến $q_i$ qua mô hình và tính $p_{qm}$ theo (2);
%     \State Tính độ tương đồng giữa $q_i$ và từng ảnh trong cơ sở dữ liệu theo (18) sử dụng LUTs, và sắp xếp kết quả theo thứ tự giảm dần;
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% Đầu tiên, toàn bộ tập ảnh trong cơ sở dữ liệu $DB = \{db_i\}_{i=1}^{|DB|}$, trong đó $db_i$ là ảnh thứ $i$ và $|DB|$  là tổng số ảnh trong cơ sở dữ liệu, được đưa qua mô hình đã huấn luyện để tiền tính toán ma trận chỉ số $B$ theo công thức. Việc này tương ứng với quá trình chia đặc trưng của mỗi ảnh thành các vector con và gán cho mỗi vector con một mã của từ mã, nhằm đảm bảo cơ sở dữ liệu được mã hoá trước khi tiến hành truy vấn.

% Tiếp theo, các bảng tra cứu nhanh được xây dựng dựa trên ma trận $B$, cho phép lưu trữ trước một phần kết quả tính toán độ tương đồng, từ đó tăng tốc độ xử lý khi truy vấn. Đối với mỗi ảnh truy vấn $q_i$ trong tập $Q = \{q_i\}_{i=1}^{|Q|} $, trong đó $q_i$ là ảnh truy vấn thứ $i$ vvà $|Q|$ là tổng số truy vấn, hệ thống thực hiện lan truyền thẳng qua mô hình để tính vector xác suất $p_{q,m}$. 

% Sau đó, độ tương đồng giữa $q_i$ và từng ảnh trong $DB$ được tính toán theo công thức (argmax) bằng cách sử dụng các LUTs, rồi sắp xếp kết quả theo thứ tự giảm dần. Cuối cùng, $k$ ảnh có độ tương đồng cao nhất được chọn làm kết quả cho $q_i$. 

% Quy trình này được lặp lại cho toàn bộ tập truy vấn $Q$, đảm bảo khả năng truy xuất đồng nhất và hiệu quả.

% Một lợi thế quan trọng của phương pháp này là khả năng tổng quát hoá cho các danh tính chưa thấy. Các phương pháp băm truyền thống thường chỉ hoạt động tốt với các danh tính đã thấy,thiếu khả năng tổng quát hoá vì chỉ học ánh xạ dựa trên các khuôn mặt đã có, không tạo được mã băm khi gặp khuôn mặt mới, khiến cho việc so sánh độ tương đồng bị sai lệch và hiệu suất truy xuất kém. Ngược lại, OPQN tận dụng bộ mã trực chuẩn và AQD để duy trì độ phân biệt giữa các đặcc trưng ngay cả khi các danh tính mới xuất hiện

% So với các phương pháp lượng tử hoá sâu hiện có như DQN và DPQ, chúng yêu cầu tái tạo lượng tử hoá mềm trực tiếp hoặc tính toán khoảng cách Ơ-clid giữa các lượng tử hoá mềm và từng từ mã, phương pháp OPQN tránh các bước này như các từ mã trực chuẩn và độc lập hoá dữ liệu. Hơn nữa các bộ mã được định nghĩa trước cho phép tái sử dụng trên các tập dữ liệu khác nhau, giảm chi phí lưu trữ hệ thống và thời gian tiền xử lý.

% Tóm lại, quy trình truy xuất dựa trên thuật toán 3 không chỉ tăng tốc độ truy vấn mà còn đảm bảo tính tổng quát hoá cho các danh tính chưa thấy, phù hợp với yêu cầu khả năng mở rộng của bài toán truy xuất hình ảnh khuôn mặt quy mô lớn. Việc tích hợp AQD và LUTs tối ưu hoá hiệu suất, trong khi tính trực chuẩn của từ mã duy trì độ chính xác và giảm độ phức tạp tính toán, khằng định tính ưu việt của phương pháp trong bối cảnh mô hình tinh gọn.

% %done