\section{EdgeFace: Mô hình nhận diện khuôn mặt hiệu quả cho các thiết bị biên}
\label{sec:edgeface-lessons}

% Giới thiệu ngắn gọn về EdgeFace

\subsection{Mô hình nhận diện khuôn mặt EdgeFace}

\subsubsection{Giới thiệu tổng quan}
EdgeFace là một mô hình nhận diện khuôn mặt lightweight được phát triển nhằm giải quyết thách thức triển khai trên \textit{thiết bị biên} (edge devices), chẳng hạn như điện thoại thông minh, camera giám sát hay các thiết bị IoT. Khác với môi trường máy chủ hoặc đám mây vốn có phần cứng mạnh mẽ, các thiết bị biên thường bị giới hạn về bộ nhớ, khả năng tính toán và mức tiêu thụ năng lượng. Vì vậy, một mô hình nhận diện khuôn mặt hiệu quả cần được thiết kế sao cho vừa đảm bảo độ chính xác cao, vừa tiết kiệm tài nguyên. 

Mục tiêu cốt lõi của EdgeFace là \textbf{tối ưu hóa hiệu quả tính toán và lưu trữ}, để có thể xử lý embedding nhanh chóng và gọn nhẹ mà không làm suy giảm đáng kể chất lượng biểu diễn đặc trưng.

\subsubsection{Thích nghi cho nhận diện khuôn mặt}
Kiến trúc EdgeFace được xây dựng dựa trên backbone của EdgeNeXt, vốn là một lightweight vision transformer được thiết kế cho các tác vụ thị giác trên thiết bị biên. Để thích nghi với bài toán nhận diện khuôn mặt, EdgeFace áp dụng hai điều chỉnh quan trọng. 

\begin{itemize}
    \item \textbf{Low Rank Linear (LoRaLin)}: thay thế các lớp tuyến tính chuẩn bằng mô-đun tuyến tính hạng thấp, giúp giảm số lượng tham số và FLOPs mà không làm giảm đáng kể độ chính xác. 
    \item \textbf{Đầu vào 112$\times$112}: điều chỉnh độ phân giải ảnh khuôn mặt để giữ lại thông tin quan trọng, đồng thời giảm chi phí tính toán.
\end{itemize}

\subsubsection{Classification Head}
Ngoài backbone EdgeNeXt đã được điều chỉnh, EdgeFace bổ sung một \textbf{classification head} chuyên biệt cho nhận diện khuôn mặt. Thành phần này bao gồm:
\begin{itemize}
    \item \textbf{Adaptive Average Pooling} để gom đặc trưng không gian về kích thước cố định.
    \item \textbf{Layer Normalization} để chuẩn hóa đặc trưng, cải thiện ổn định khi huấn luyện.
    \item \textbf{LoRaLin Layer} để ánh xạ đặc trưng sang vector embedding \textbf{512 chiều}, phục vụ nhận diện và truy hồi.
\end{itemize}

\subsubsection{Minh họa kiến trúc}
Kiến trúc tổng thể của EdgeFace được minh họa trong Hình~1 của bài báo gốc~\cite{george2024edgeface}. Sơ đồ này thể hiện backbone EdgeNeXt với các stage tuần tự, trong đó mỗi stage sử dụng bộ mã hóa SDTA (Split Depth-wise Transpose Attention). Classification head được gắn ở cuối để tạo embedding 512 chiều. Sự kết hợp này làm nổi bật tính chất lai (CNN + Transformer) và tính hiệu quả của EdgeFace.

Nhớ thêm sơ đồ vào đây
\subsubsection{Kết luận}
Tóm lại, EdgeFace là một mô hình lightweight hiệu quả cho nhận diện khuôn mặt trên thiết bị biên. Kiến trúc này kế thừa EdgeNeXt, kết hợp với \textbf{LoRaLin} để giảm tham số và FLOPs, đồng thời bổ sung \textbf{classification head} nhằm tạo embedding 512 chiều chất lượng cao. Nhờ đó, EdgeFace vừa duy trì độ chính xác, vừa đảm bảo hiệu quả tính toán và lưu trữ, phù hợp cho cả triển khai tại biên lẫn các hệ thống truy hồi khuôn mặt quy mô lớn.

% Giới thiệu tổng quan về edgeface
%% Trình bày EdgeFce là mô hình nhận diện khuôn mặt nhẹ, thiết kế cho thiết bị biên
%% Nêu rõ mục tiêu tối ưu hóa hiệu quả tính toán và lưu trữ

% Thích nghi cho nhận diện khuôn mặt
%% Mô tả Edgeface dựa trên kiến trúc Edgenext, với các lớp linear được thay bằng Low Rank Linear(loRaLin) để giảm tham số và FLOPs.
%% Đề cập điều chỉnh độ phân giải đầu vào thành 112x112 cho phù hợp với nhận diện khuôn mặt


% Classification Head 
%% giới thiệu classification Head gồm : Adaptive Average Pooling, LayerNorm, LoRaLin layer(tạo embedding 512 chiều)

%Minh họa kiến trúc 
%% Nhắc đến hình 1 trong bài báo gốc [George et al., 2024], minh họa sơ đồ kiến trúc EdgeFace, bao gồm các stage với bộ mã hóa 


% Kết luận ngắn gọn 
%% Tóm tắt EdgeFace là mô hình hiệu quả, sử dụng LoRaLin và classification head để tạo embedding chất lượng cao 



\subsection{Kiến trúc EdgeNeXt}

EdgeNeXt là một kiến trúc thị giác lai (\textit{hybrid architecture}) kết hợp giữa \textbf{Convolutional Neural Network (CNN)} và \textbf{Transformer}. Mục tiêu của EdgeNeXt là khai thác điểm mạnh của cả hai hướng tiếp cận: CNN hiệu quả trong việc trích xuất đặc trưng cục bộ, trong khi Transformer có khả năng mô hình hóa ngữ cảnh toàn cục. Bằng cách kết hợp, EdgeNeXt vừa giữ được độ chính xác cao, vừa duy trì chi phí tính toán thấp, phù hợp để triển khai trên \textit{thiết bị biên}. 

Khác với ConvNeXt – mô hình gốc mà EdgeNeXt phát triển từ đó – EdgeNeXt được thiết kế lại với các cơ chế tính toán nhẹ hơn, nhằm giảm số tham số và phép nhân-cộng (MAdds), đồng thời vẫn đảm bảo hiệu quả trên các tác vụ thị giác máy tính quy mô lớn.

\subsubsection{Bộ mã hóa Split Depth-wise Transpose Attention (SDTA)}
Trọng tâm đổi mới của EdgeNeXt nằm ở \textbf{SDTA encoder}, một khối mã hóa đặc trưng gọn nhẹ nhưng mạnh mẽ. Cơ chế của SDTA bao gồm:
\begin{itemize}
    \item \textbf{Phân chia nhóm kênh}: tensor đầu vào được tách thành nhiều nhóm kênh để xử lý song song, giúp giảm tải tính toán.
    \item \textbf{Depth-wise convolution}: áp dụng tích chập theo từng kênh để nắm bắt thông tin cục bộ với chi phí rẻ.
    \item \textbf{Self-attention dạng hoán vị}: sử dụng truy vấn (query) và khóa (key) được hoán vị theo chiều kênh, cho phép tính toán attention với độ phức tạp tuyến tính thay vì bậc hai.
\end{itemize}

Nhờ thiết kế này, SDTA mở rộng được \textit{trường tiếp nhận} (receptive field) mà không cần tăng nhiều tham số. Kết quả là mô hình có thể biểu diễn đặc trưng đa tỷ lệ (\textit{multi-scale features}), rất quan trọng cho các tác vụ nhận diện và phân loại ảnh.

\subsubsection{Kernel thích ứng}
Để tăng cường khả năng mô hình hóa thông tin toàn cục, EdgeNeXt sử dụng \textbf{kernel tích chập thích ứng} qua từng giai đoạn (stage). Cụ thể, các lớp đầu thường sử dụng kernel nhỏ (ví dụ: $3 \times 3$) nhằm tập trung vào chi tiết cục bộ, trong khi các lớp sâu hơn chuyển sang kernel lớn hơn (ví dụ: $9 \times 9$) để khai thác thông tin toàn ảnh. Cách tiếp cận này cho phép mô hình dần dần tích hợp ngữ cảnh rộng hơn mà không làm chi phí tính toán tăng đột biến.

\subsubsection{Các biến thể của EdgeNeXt}
Để đáp ứng đa dạng yêu cầu tài nguyên, EdgeNeXt được triển khai dưới nhiều biến thể: \textbf{Small}, \textbf{X-Small} và \textbf{XX-Small}. Các phiên bản này khác nhau về độ sâu mạng, số kênh đặc trưng và tổng tham số, từ đó cho phép người dùng cân nhắc giữa độ chính xác và chi phí tính toán. Bảng~1 trong bài báo gốc~\cite{george2024edgeface} minh họa chi tiết cấu trúc lớp, số kênh và đầu ra của từng biến thể, cung cấp sự linh hoạt cao trong triển khai thực tế.

\subsubsection{Hiệu suất và minh họa}
Theo các thực nghiệm trong~\cite{george2024edgeface}, EdgeNeXt đạt hiệu suất vượt trội so với nhiều mô hình lightweight khác như MobileViT hay EdgeFormer, đặc biệt trong tác vụ phân loại ảnh. Ưu điểm nổi bật là đạt độ chính xác tương đương hoặc cao hơn trong khi chi phí tính toán thấp hơn đáng kể. Ngoài ra, sơ đồ cấu trúc và thông số minh họa ở Bảng~1 cung cấp cái nhìn trực quan về cách EdgeNeXt đạt được sự cân bằng giữa độ chính xác và hiệu quả tính toán.\\



\begin{table}[ht]
  \caption{So sánh các mô hình lightweight: EdgeNeXt, MobileViT, EdgeFormer, EdgeFace(Số liệu ảo)}
  \label{tab:compare_lightweight}
  \centering
  \begin{tabularx}{\textwidth}{l c c p{3cm} p{3.2cm}}
    \toprule
    \textbf{Mô hình} & \textbf{Tham số} & \textbf{MAdds} & \textbf{Độ chính xác} & \textbf{Ghi chú} \\
    \midrule
    EdgeNeXt (Small) & $\sim$1.3M & thấp & Top-1 $\approx$ 71.2\% (ImageNet) & Giảm FLOPs $\sim$28\% so với MobileViT \\
    MobileViT & — & — & — & Đối thủ lightweight CNN–Transformer \\
    EdgeFormer & — & — & — & Mô hình lai lightweight, dùng cho biên \\
    EdgeFace & $\sim$1.77M & — & LFW 99.73\%; IJB-B 92.67\%; IJB-C 94.85\% & Tối ưu dưới 2M tham số, dùng LoRaLin \\
    \bottomrule
  \end{tabularx}
\end{table} \\



Tóm lại, EdgeNeXt là một kiến trúc lai kết hợp CNN và Transformer, trong đó SDTA encoder và kernel thích ứng đóng vai trò trung tâm. Nhờ thiết kế này, EdgeNeXt đạt được sự cân bằng giữa khả năng biểu diễn và chi phí tính toán, trở thành lựa chọn phù hợp cho các ứng dụng thị giác trên thiết bị biên.

%Mở đầu: Giới thiệu tổng quan về EdgeNeXt

%%Trình bày EdgeNeXt là một kiến trúc hybrid kết hợp CNN và Transformer, được thiết kế để tối ưu cho thiết bị biên với số lượng tham số và phép tính (MAdds) thấp.
%%Nêu rõ EdgeNeXt phát triển dựa trên ConvNeXt, cải tiến để phù hợp cho các ứng dụng thị giác máy tính.

%Split Depth-wise Transpose Attention (SDTA) Encoder

%%Mô tả SDTA là thành phần cốt lõi, phân chia tensor đầu vào thành các nhóm kênh.
%%Giải thích cơ chế: Sử dụng depth-wise convolution kết hợp self-attention theo chiều kênh (transposed query-key) để đạt độ phức tạp tuyến tính.
%%Nêu vai trò của SDTA: Mở rộng trường tiếp nhận (receptive field) và mã hóa đặc trưng đa tỷ lệ (multi-scale).

%Kernel thích ứng

%%Mô tả việc sử dụng kernel kích thước khác nhau qua các stage (3x3 ở lớp đầu, lớn hơn như 9x9 ở lớp sau) để thu thập thông tin toàn cục.
%%Đề cập rằng kernel thích ứng giúp tăng cường khả năng mã hóa đặc trưng toàn cục.

%Các biến thể của EdgeNeXt

%%Giới thiệu các biến thể: Small, X-Small, XX-Small, với kích thước đặc trưng và tham số khác nhau (tham khảo Table 1 trong bài báo gốc [George et al., 2024]).
%%Nêu rõ các biến thể cung cấp tính linh hoạt tùy thuộc vào yêu cầu tài nguyên.

%Hiệu suất và minh họa

%%Nhắc đến hiệu suất của EdgeNeXt: Vượt trội so với MobileViT và EdgeFormer trong nhận diện hình ảnh với chi phí tính toán thấp.
%%Đề cập Table 1 minh họa cấu trúc lớp, kích thước đầu ra, và số kênh cho các biến thể.

%Kết luận ngắn gọn

%%Tóm tắt rằng EdgeNeXt kết hợp CNN và Transformer với SDTA và kernel thích ứng, cung cấp kiến trúc hiệu quả cho các ứng dụng trên thiết bị biên.

\subsection{Mô-đun tuyến tính hạng thấp(LoRaLin)}

 
Trong các kiến trúc học sâu, đặc biệt là trong các mô hình nhận diện khuôn mặt, các lớp tuyến tính (\textit{fully connected layers}) thường chiếm một tỷ lệ lớn số tham số và chi phí tính toán. Để giải quyết thách thức này trong bối cảnh triển khai trên thiết bị biên, EdgeFace giới thiệu \textbf{Low Rank Linear Module (LoRaLin)} như một cải tiến quan trọng. Mục tiêu của LoRaLin là giảm đáng kể số lượng tham số và phép tính (\textit{Multiply-Adds, MAdds}) trong khi chỉ làm suy giảm hiệu suất ở mức tối thiểu.

\paragraph{Cơ chế phân tích low-rank.} 
Ý tưởng cốt lõi của LoRaLin là phân tích ma trận trọng số full-rank thành hai ma trận hạng thấp. Cho một lớp tuyến tính chuẩn với ma trận trọng số $W \in \mathbb{R}^{M \times N}$, LoRaLin thay thế bằng tích của hai ma trận nhỏ hơn:
\[
    W_{M \times N} \approx W_{M \times r} \cdot W_{r \times N},
\]
trong đó $r$ là \textit{rank} được xác định theo công thức:
\[
    r = \max(2, \gamma \cdot \min(M,N)),
\]
với $\gamma$ là tham số \textit{rank-ratio}. Cách tiếp cận này tương đương với việc thay thế một lớp tuyến tính duy nhất bằng hai lớp tuyến tính liên tiếp: lớp thứ nhất giảm chiều xuống $r$, và lớp thứ hai ánh xạ trở lại không gian đầu ra. Hình~2 trong bài báo gốc~\cite{george2024edgeface} minh họa trực quan cơ chế này.\\
\begin{figure}[ht]
    \centering
 

% Trong nội dung
\begin{minted}[fontsize=\footnotesize, frame=single, linenos]{python}
class LoRaLin(nn.Module):
    def __init__(self, in_feat, out_feat, gamma, bias=True):
        super(LoRaLin, self).__init__()
        rank = max(2, int(min(in_feat, out_feat) * gamma))
        self.lin1 = nn.Linear(in_feat, rank, bias=False)
        self.lin2 = nn.Linear(rank, out_feat, bias=bias)

    def forward(self, input):
        x = self.lin1(input)
        x = self.lin2(x)
        return x
\end{minted}

    \caption{Minh họa lớp \textit{Low-Rank Linear} (LoRaLin) được cài đặt bằng PyTorch. 
    Thay vì sử dụng một lớp fully connected duy nhất kích thước $M \times N$, LoRaLin phân rã ma trận thành hai lớp tuyến tính hạng thấp có kích thước $M \times r$ và $r \times N$, 
    với $r$ được xác định bởi tham số \textit{Rank-ratio} ($\gamma$). 
    Cách triển khai này cho phép giảm đáng kể số lượng tham số và phép tính (FLOPs) trong khi vẫn duy trì độ chính xác gần như không đổi.}
    \label{fig:lora_lin}
\end{figure}



\paragraph{Điều chỉnh Rank-ratio ($\gamma$).} 
Tham số $\gamma$ quyết định mức độ giảm hạng và do đó ảnh hưởng trực tiếp đến số tham số và FLOPs. Kết quả thực nghiệm (Hình~3 trong~\cite{george2024edgeface}) cho thấy:
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.65\textwidth]{images/fig3.2.3.png} % đường dẫn 
    \caption{Ảnh hưởng của tham số \textit{Rank-ratio} ($\gamma$) đến số lượng tham số của mô hình (MPARAMS) và số phép nhân-cộng (MFLOPs). 
    Đường nét đứt thể hiện giá trị tham chiếu của mô hình gốc khi sử dụng lớp tuyến tính thông thường. 
    Có thể thấy khi $\gamma$ giảm, số tham số và FLOPs giảm đáng kể, trong khi vẫn duy trì hiệu suất gần như không đổi.}
    \label{fig:lora_lin_rank}
    
\end{figure}

\begin{itemize}
    \item Khi $\gamma < 0.8$, số tham số và FLOPs giảm đáng kể so với lớp tuyến tính chuẩn.
    \item Ở $\gamma \approx 0.6$, EdgeFace đạt \textbf{sự cân bằng tối ưu}: giảm khoảng $20\%$ số tham số và FLOPs, trong khi suy giảm hiệu suất dưới $0.5\%$.
\end{itemize}
Điều này chứng tỏ LoRaLin mang lại khả năng nén mô hình hiệu quả với trade-off tối thiểu về độ chính xác.

\paragraph{Triển khai và minh họa.} 
Trong PyTorch, LoRaLin có thể được triển khai đơn giản bằng cách xâu chuỗi hai lớp tuyến tính:
\begin{itemize}
    \item \texttt{lin1}: ánh xạ từ \texttt{in\_feat} $\to$ \texttt{rank}.
    \item \texttt{lin2}: ánh xạ từ \texttt{rank} $\to$ \texttt{out\_feat}.
\end{itemize}
Nhờ thiết kế này, LoRaLin có thể thay thế trực tiếp các lớp tuyến tính truyền thống trong EdgeFace mà không làm phức tạp thêm quá trình huấn luyện hay suy luận. Trên thực tế, toàn bộ các lớp fully connected trong EdgeFace đều được thay bằng LoRaLin để tối ưu hiệu quả tính toán.

\paragraph{Kết luận.} 
Tóm lại, \textbf{LoRaLin} là một giải pháp gọn nhẹ và hiệu quả để giảm số tham số và FLOPs trong các lớp fully connected. Với cơ chế phân tích hạng thấp và khả năng điều chỉnh linh hoạt qua $\gamma$, LoRaLin cho phép EdgeFace duy trì chất lượng biểu diễn embedding gần như không suy giảm, đồng thời đáp ứng yêu cầu triển khai trên thiết bị biên.

\subsection{Chi tiết huấn luyện}
\subsubsection{Chiến lược huấn luyện}

EdgeFace được huấn luyện nhằm tối ưu hóa hiệu suất nhận diện khuôn mặt trong điều kiện hạn chế tài nguyên trên thiết bị biên. 
Quy trình huấn luyện tận dụng tập dữ liệu quy mô lớn kết hợp với các chiến lược tối ưu hóa để vừa nâng cao độ chính xác, vừa duy trì tính gọn nhẹ của mô hình \cite{George2024}.

\textbf{Dataset.} Mô hình được huấn luyện trên các tập con WebFace12M và WebFace4M, được trích xuất từ WebFace260M. 
Các ảnh trong tập dữ liệu này đã được căn chỉnh khuôn mặt và chuẩn hóa độ phân giải về $112\times112$, phù hợp với tiêu chuẩn của các hệ thống nhận diện khuôn mặt.

\textbf{Tiền xử lý và tăng cường dữ liệu.} Dữ liệu đầu vào được chuyển đổi thành tensor và chuẩn hóa về khoảng $[-1,1]$. 
Quá trình tăng cường dữ liệu được thực hiện bằng thư viện DALI, bao gồm các phép biến đổi như chuyển đổi ngẫu nhiên sang thang xám, thay đổi kích thước, và làm mờ, nhằm tăng tính đa dạng và tính khái quát của mô hình.

\textbf{Chi tiết huấn luyện.} Mô hình được huấn luyện trên 4--8 GPU Nvidia RTX 3090 (24GB) với chiến lược \textit{distributed training}. 
Optimizer AdamW kết hợp với hàm mất mát CosFace được sử dụng để tối ưu embedding. 
Lịch trình learning rate theo \textit{polynomial decay with restarts} giúp mô hình hội tụ ổn định. 
Batch size dao động từ 256 đến 512 tùy thuộc vào kích thước mô hình, và PartialFC được áp dụng để xử lý số lượng lớn danh tính trong tập dữ liệu.

\textbf{Inference.} Trong giai đoạn suy luận, \textit{classification head} được loại bỏ. 
Mô hình chỉ sử dụng vector embedding 512 chiều làm biểu diễn đặc trưng cho so sánh và truy hồi khuôn mặt.

Tóm lại, quy trình huấn luyện của EdgeFace kết hợp dữ liệu quy mô lớn, tiền xử lý hiệu quả, và các kỹ thuật tối ưu hóa hiện đại, từ đó đạt được hiệu suất cao trong khi vẫn đảm bảo khả năng triển khai trên thiết bị biên.
